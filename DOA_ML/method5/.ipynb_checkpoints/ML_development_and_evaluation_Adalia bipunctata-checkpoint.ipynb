{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8249e7",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#일반-log-정규화만\" data-toc-modified-id=\"일반-log-정규화만-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>일반 log 정규화만</a></span><ul class=\"toc-item\"><li><span><a href=\"#변수-추출\" data-toc-modified-id=\"변수-추출-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>변수 추출</a></span><ul class=\"toc-item\"><li><span><a href=\"#통계적-검증\" data-toc-modified-id=\"통계적-검증-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>통계적 검증</a></span><ul class=\"toc-item\"><li><span><a href=\"#독립선형회귀분석(scipy)을-거친-경우\" data-toc-modified-id=\"독립선형회귀분석(scipy)을-거친-경우-1.1.1.1\"><span class=\"toc-item-num\">1.1.1.1&nbsp;&nbsp;</span>독립선형회귀분석(scipy)을 거친 경우</a></span></li><li><span><a href=\"#처음부터-다중선형회귀분석으로-직행하는-경우\" data-toc-modified-id=\"처음부터-다중선형회귀분석으로-직행하는-경우-1.1.1.2\"><span class=\"toc-item-num\">1.1.1.2&nbsp;&nbsp;</span>처음부터 다중선형회귀분석으로 직행하는 경우</a></span></li><li><span><a href=\"#결과-종합\" data-toc-modified-id=\"결과-종합-1.1.1.3\"><span class=\"toc-item-num\">1.1.1.3&nbsp;&nbsp;</span>결과 종합</a></span></li><li><span><a href=\"#다중공산성\" data-toc-modified-id=\"다중공산성-1.1.1.4\"><span class=\"toc-item-num\">1.1.1.4&nbsp;&nbsp;</span>다중공산성</a></span></li></ul></li></ul></li><li><span><a href=\"#머신러닝\" data-toc-modified-id=\"머신러닝-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>머신러닝</a></span><ul class=\"toc-item\"><li><span><a href=\"#압축-전(변수-10개)\" data-toc-modified-id=\"압축-전(변수-10개)-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>압축 전(변수 10개)</a></span></li></ul></li><li><span><a href=\"#check-point\" data-toc-modified-id=\"check-point-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>check point</a></span></li></ul></li><li><span><a href=\"#머신러닝\" data-toc-modified-id=\"머신러닝-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>머신러닝</a></span></li><li><span><a href=\"#SHAP\" data-toc-modified-id=\"SHAP-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SHAP</a></span></li><li><span><a href=\"#실전-테스트\" data-toc-modified-id=\"실전-테스트-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>실전 테스트</a></span></li><li><span><a href=\"#그-밖의-통계-결과\" data-toc-modified-id=\"그-밖의-통계-결과-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>그 밖의 통계 결과</a></span><ul class=\"toc-item\"><li><span><a href=\"#결정트리\" data-toc-modified-id=\"결정트리-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>결정트리</a></span></li><li><span><a href=\"#앙상블학습\" data-toc-modified-id=\"앙상블학습-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>앙상블학습</a></span></li><li><span><a href=\"#랜덤-포레스트\" data-toc-modified-id=\"랜덤-포레스트-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>랜덤 포레스트</a></span><ul class=\"toc-item\"><li><span><a href=\"#GBM\" data-toc-modified-id=\"GBM-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>GBM</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced-learn 패키지\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from urllib.request import Request # 서버 요청 객체를 생성하는 모듈\n",
    "import urllib.request\n",
    "from tqdm import tqdm_notebook # 반복문의 반복 요소에 적용시키면 반복요소가 얼마나 진행되었는지 상태바를 표시\n",
    "from tqdm import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt #그래프 패키지 모듈 등록\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas\n",
    "from haversine import haversine\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_seq_items', None) # 한 줄 내 표현\n",
    "\n",
    "from sklearn.datasets import load_iris # sklearn.datasets - 자체 제공 데이터\n",
    "from sklearn.tree import DecisionTreeClassifier # sklearn.알고리즘명 - ML 알고리즘을 구현한 클래스 집합\n",
    "from sklearn.model_selection import train_test_split # sklearn.model_selection - 데이터 분리, 최적의 하이퍼파라미터 평가 등\n",
    "from sklearn.metrics import accuracy_score # sklearn.metrics 평가 등\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.formula.api import ols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# 사이킷런 래퍼 XGBoost 클래스인 XGBClassifier 임포트\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pygraphviz as pgv\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "    \n",
    "\n",
    "def get_clf_eval_num(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "\n",
    "def get_clf_eval_num_easy(y_test, pred=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eec9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "#     print('오차 행렬')\n",
    "#     print(confusion)\n",
    "#     # ROC-AUC print 추가\n",
    "#     print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "#     F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04710fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "allpot = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12888ee6",
   "metadata": {},
   "source": [
    "# 일반 log 정규화만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c92 = pd.read_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20220210_Newgeneration_new_speices/bipunctata/20220210_DOA_log화_bipunc.csv', index_col = 0)\n",
    "# c92 = c92.drop([3117,950,995,2843,2969,177,70,116,15,213,640,342,2900,59,\n",
    "# 470,2953,2924,471,2933,639,429,531,783,621,126,472,433,619,2946,\n",
    "# 3083,977,2922,975,546,762,344,953,2834,530,637,529,787,955,786,\n",
    "# 992,1044,872,1009,812])\n",
    "# c92.reset_index(inplace=True, drop=True)\n",
    "# c92.to_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20220210_Newgeneration_new_speices/bipunctata/20220210_DOA_log화_bipunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX scaling\n",
    "c92 = pd.read_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20220220_최신 데이터 세트/220220_DOA_bi(최종,minmax).csv', index_col = 0)\n",
    "\n",
    "# log scaling\n",
    "# c92 = pd.read_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20220220_최신 데이터 세트/220220_DOA_bi(최종,log).csv', index_col = 0)\n",
    "\n",
    "\n",
    "######(option) 반경 18 km 이내에 C9있는 absence 제외\n",
    "c92 = c92.drop(c92[(c92['Adalia bipunctata_18']!=0)&(c92['Species']!='Adalia bipunctata')].index)\n",
    "\n",
    "#### 히포다이마 제와 및 C9 + axy만 absence인 버전\n",
    "# c92 = c92.drop(c92[c92['Species'] == 'Hippodamia convergens'].index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13732b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92.columns\n",
    "\n",
    "# c92 = c92[c92.Year > 2008].reset_index(drop=True)\n",
    "\n",
    "c92 = c92.sort_values(by='Species').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "c92_n = c92[['Species','Harmonia axyridis_18',\n",
    "       'Coccinella septempunctata_18', 'Hippodamia convergens_18',\n",
    "       'Coelophora maculata_18', 'Cycloneda sanguinea_18',\n",
    "       'Propylea quatuordecimpunctata_18', 'Cycloneda munda_18',\n",
    "       'Psyllobora vigintimaculata_18', 'Chilocorus stigma_18',\n",
    "       'Olla v-nigrum_18', 'Hippodamia variegata_18', # 'Adalia bipunctata_18',\n",
    "       'Coccinella californica_18', 'Cycloneda polita_18',\n",
    "       'Cryptolaemus montrouzieri_18', 'Coccinella trifasciata_18',\n",
    "       'Epilachna borealis_18', 'Anatis mali_18', 'Chilocorus cacti_18',\n",
    "       'Brachiacantha ursina_18', 'Hippodamia parenthesis_18',\n",
    "       'Anatis labiculata_18', 'Mulsantina picta_18',\n",
    "       'Coccinella transversoguttata_18', 'Psyllobora renifer_18',\n",
    "       'Naemia seriata_18', 'Hippodamia tredecimpunctata_18',\n",
    "       'Epilachna varivestis_18', 'Coccinella novemnotata_18',\n",
    "       'Hippodamia glacialis_18', 'Anatis lecontei_18', 'Axion plagiatum_18',\n",
    "       'Calvia quatuordecimguttata_18', 'Coleomegilla maculata_18',\n",
    "       'Stethorus punctillum_18', 'Anatis rathvoni_18',\n",
    "       'Psyllobora borealis_18', 'Curinus coeruleus_18', 'Myzia pullata_18',\n",
    "       'Halmus chalybeus_18', 'Neoharmonia venusta_18',\n",
    "       'Exochomus childreni_18', 'Hippodamia caseyi_18',\n",
    "       'Coelophora inaequalis_18', 'Coccinella monticola_18',\n",
    "       'Mulsantina hudsonica_18', 'Anisosticta bitriangularis_18',\n",
    "       'Hyperaspis binotata_18', 'Diomus terminatus_18',\n",
    "       'Exochomus quadripustulatus_18', 'Hippodamia sinuata_18',\n",
    "       'Brumoides septentrionis_18', 'Hippodamia quinquesignata_18',\n",
    "       'Hyperaspis bigeminata_18', 'Paranaemia vittigera_18',\n",
    "       'Chilocorus bipustulatus_18', 'Rhyzobius lophanthae_18',\n",
    "       'Novius cardinalis_18', 'Brachiacantha decempustulata_18',\n",
    "       'Scymnus loewii_18', 'Scymnus nebulosus_18', 'Didion punctatum_18',\n",
    "       'Stethorus punctum_18', 'Myzia interrupta_18',\n",
    "       'Hyperaspis trifurcata_18', 'Axion tripustulatum_18',\n",
    "       'Epilachna tredecimnotata_18',\n",
    "       'Subcoccinella vigintiquatuorpunctata_18', 'Hippodamia apicalis_18',\n",
    "       'Hyperaspis undulata_18', 'Exochomus aethiops_18',\n",
    "       'Hyperaspis lateralis_18', 'Coccinella hieroglyphica_18',\n",
    "       'Hyperaspis quadrioculata_18', 'Microweisea misella_18',\n",
    "       'Exochomus marginipennis_18', 'Hippodamia oregonensis_18',\n",
    "       'Myzia subvittata_18', 'Brachiacantha dentipes_18',\n",
    "       'Psyllobora parvinotata_18', 'Nephus flavifrons_18',\n",
    "       'Brachiacantha quadripunctata_18', 'Hyperaspis proba_18',\n",
    "       'Egius platycephalus_18', 'Hyperaspis connectens_18',\n",
    "       'Nephus intrusus_18', 'Exochomus fasciatus_18', 'Scymnus louisianae_18',\n",
    "       'Coccinella undecimpunctata_18', 'Delphastus pusillus_18',\n",
    "       'Eremophila alpestris_18', 'Lanius ludovicianus_18',\n",
    "       'Plectrophenax nivalis_18', 'Phainopepla nitens_18',\n",
    "       'Lanius borealis_18', 'Calcarius lapponicus_18', 'Cinclus mexicanus_18',\n",
    "       'Lonchura punctulata_18', 'Zosterops japonicus_18',\n",
    "       'Centronyx henslowii_18', 'Paroaria coronata_18',\n",
    "       'Calcarius ornatus_18', 'Passer montanus_18', 'Pycnonotus cafer_18',\n",
    "       'Sicalis flaveola_18', 'Estrilda astrild_18', 'Pycnonotus jocosus_18',\n",
    "       'Copsychus malabaricus_18', 'Rhynchophanes mccownii_18',\n",
    "       'Paroaria capitata_18', 'Leiothrix lutea_18',\n",
    "       'Peucedramus taeniatus_18', 'Lonchura atricapilla_18',\n",
    "       'Centronyx bairdii_18', 'Chasiempis sandwichensis_18',\n",
    "       'Euodice cantans_18', 'Vidua macroura_18', 'Horornis diphone_18',\n",
    "       'Garrulax canorus_18', 'Calcarius pictus_18', 'Zosterops simplex_18',\n",
    "       'Alauda arvensis_18', 'Oenanthe oenanthe_18',\n",
    "       'Euplectes franciscanus_18', 'Phylloscopus borealis_18',\n",
    "       'Amandava amandava_18', 'Chasiempis sclateri_18',\n",
    "       'Sporophila torqueola_18', 'Luscinia svecica_18', 'Estrilda melpoda_18',\n",
    "       'Chasiempis ibidis_18', 'Pachyramphus aglaiae_18',\n",
    "       'Plectrophenax hyperboreus_18', 'Prunella montanella_18',\n",
    "       'Spindalis zena_18', 'Tarsiger cyanurus_18', 'Coereba flaveola_18',\n",
    "       'Tiaris olivaceus_18', 'Phylloscopus fuscatus_18', 'Lanius collurio_18',\n",
    "       'Muscicapa griseisticta_18', 'Phylloscopus inornatus_18',\n",
    "       'Lanius cristatus_18', 'Acrocephalus familiaris_18',\n",
    "       'Phylloscopus trochilus_18', 'Muscicapa sibirica_18',\n",
    "       'Ficedula albicilla_18', 'Estrilda troglodytes_18',\n",
    "       'Phylloscopus collybita_18', 'Lonchura malacca_18',\n",
    "       'Saxicola maurus_18', 'Larvivora sibilans_18',\n",
    "       'Phylloscopus examinandus_18', 'Erithacus rubecula_18',\n",
    "       'Locustella lanceolata_18', 'Cyanerpes cyaneus_18',\n",
    "       'Acrocephalus schoenobaenus_18', 'Acrocephalus dumetorum_18',\n",
    "       'Locustella fluviatilis_18', 'Uraeginthus bengalus_18',\n",
    "       'Luscinia cyane_18', 'Phoenicurus phoenicurus_18',\n",
    "       'Taeniopygia guttata_18', 'Pachyramphus major_18',\n",
    "       'Oenanthe pleschanka_18']]\n",
    "\n",
    "\n",
    "c92_n['Species']\n",
    "        \n",
    "c92_n['Species_1'] = c92_n['Species']\n",
    "c92_n['Species_18'] = c92_n['Species']\n",
    "\n",
    "\n",
    "c92_05 = c92_n.filter(regex='0.5')\n",
    "c92_1 = c92_n.filter(regex='_1') # 이거 18과 구분 필요\n",
    "c92_2 = c92_n.filter(regex='_2')\n",
    "c92_4 = c92_n.filter(regex='_4')\n",
    "c92_8 = c92_n.filter(regex='_8')\n",
    "c92_18 = c92_n.filter(regex='_18')\n",
    "\n",
    "c92_1 = c92_n[list(set(c92_1.columns) - set(c92_18.columns))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ff92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_1['target'] = 0\n",
    "for i in c92_1.index:\n",
    "    if c92_1['Species_1'][i] == 'Adalia bipunctata':\n",
    "        c92_1['target'][i] = 1\n",
    "\n",
    "c92_1['target']\n",
    "\n",
    "\n",
    "c92_18['target'] = 0\n",
    "for i in c92_18.index:\n",
    "    if c92_18['Species_18'][i] == 'Adalia bipunctata':\n",
    "        c92_18['target'][i] = 1\n",
    "\n",
    "c92_18['target']\n",
    "\n",
    "c92zet = pd.merge(c92[['Source', 'Year', 'Species', 'Latitude', 'Longitude',\n",
    "       'public_positional_accuracy', 'State', 'gps']], c92_18, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 프레임 정렬\n",
    "\n",
    "c92_18 = c92_18.sort_values(by='target', ascending=False).reset_index(drop=True)\n",
    "c92_18['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2a8d9",
   "metadata": {},
   "source": [
    "## 변수 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2647605",
   "metadata": {},
   "source": [
    "### 통계적 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52131bf",
   "metadata": {},
   "source": [
    "#### 독립선형회귀분석(scipy)을 거친 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52653847",
   "metadata": {},
   "source": [
    "##### 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe70e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa45338",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e919039",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92 = c92_18.copy()\n",
    "\n",
    "# 관측건수 50으로 자른후의 회귀분석결과\n",
    "\n",
    "\n",
    "from scipy.stats import *\n",
    "\n",
    "jazz = ['Harmonia axyridis_18', 'Coccinella septempunctata_18',\n",
    "       'Hippodamia convergens_18', 'Coelophora maculata_18',\n",
    "       'Cycloneda sanguinea_18', 'Propylea quatuordecimpunctata_18',\n",
    "       'Cycloneda munda_18', 'Psyllobora vigintimaculata_18',\n",
    "       'Chilocorus stigma_18', 'Olla v-nigrum_18', 'Hippodamia variegata_18',\n",
    "       'Coccinella californica_18', 'Cycloneda polita_18',\n",
    "       'Cryptolaemus montrouzieri_18', 'Coccinella trifasciata_18',\n",
    "       'Epilachna borealis_18', 'Anatis mali_18', 'Chilocorus cacti_18',\n",
    "       'Brachiacantha ursina_18', 'Hippodamia parenthesis_18',\n",
    "       'Anatis labiculata_18', 'Mulsantina picta_18',\n",
    "       'Coccinella transversoguttata_18', 'Psyllobora renifer_18',\n",
    "       'Naemia seriata_18', 'Hippodamia tredecimpunctata_18',\n",
    "       'Epilachna varivestis_18', 'Coccinella novemnotata_18',\n",
    "       'Hippodamia glacialis_18', 'Anatis lecontei_18', 'Axion plagiatum_18',\n",
    "       'Calvia quatuordecimguttata_18', 'Coleomegilla maculata_18',\n",
    "       'Stethorus punctillum_18', 'Anatis rathvoni_18',\n",
    "       'Psyllobora borealis_18', 'Curinus coeruleus_18', 'Myzia pullata_18',\n",
    "       'Halmus chalybeus_18', 'Neoharmonia venusta_18',\n",
    "       'Exochomus childreni_18', 'Hippodamia caseyi_18',\n",
    "       'Coelophora inaequalis_18', 'Coccinella monticola_18',\n",
    "       'Mulsantina hudsonica_18', 'Anisosticta bitriangularis_18',\n",
    "       'Hyperaspis binotata_18', 'Diomus terminatus_18',\n",
    "       'Exochomus quadripustulatus_18', 'Hippodamia sinuata_18',\n",
    "       'Brumoides septentrionis_18', 'Hippodamia quinquesignata_18',\n",
    "       'Hyperaspis bigeminata_18', 'Paranaemia vittigera_18',\n",
    "       'Chilocorus bipustulatus_18', 'Rhyzobius lophanthae_18',\n",
    "       'Novius cardinalis_18', 'Brachiacantha decempustulata_18',\n",
    "       'Scymnus loewii_18', 'Scymnus nebulosus_18', 'Didion punctatum_18',\n",
    "       'Stethorus punctum_18', 'Myzia interrupta_18',\n",
    "       'Hyperaspis trifurcata_18', 'Axion tripustulatum_18',\n",
    "       'Epilachna tredecimnotata_18',\n",
    "       'Subcoccinella vigintiquatuorpunctata_18', 'Hippodamia apicalis_18',\n",
    "       'Hyperaspis undulata_18', 'Exochomus aethiops_18',\n",
    "       'Hyperaspis lateralis_18', 'Coccinella hieroglyphica_18',\n",
    "       'Hyperaspis quadrioculata_18', 'Microweisea misella_18',\n",
    "       'Exochomus marginipennis_18', 'Hippodamia oregonensis_18',\n",
    "       'Myzia subvittata_18', 'Brachiacantha dentipes_18',\n",
    "       'Psyllobora parvinotata_18', 'Nephus flavifrons_18',\n",
    "       'Brachiacantha quadripunctata_18', 'Hyperaspis proba_18',\n",
    "       'Egius platycephalus_18', 'Hyperaspis connectens_18',\n",
    "       'Nephus intrusus_18', 'Exochomus fasciatus_18', 'Scymnus louisianae_18',\n",
    "       'Coccinella undecimpunctata_18', 'Delphastus pusillus_18',\n",
    "       'Eremophila alpestris_18', 'Lanius ludovicianus_18',\n",
    "       'Plectrophenax nivalis_18', 'Phainopepla nitens_18',\n",
    "       'Lanius borealis_18', 'Calcarius lapponicus_18', 'Cinclus mexicanus_18',\n",
    "       'Lonchura punctulata_18', 'Zosterops japonicus_18',\n",
    "       'Centronyx henslowii_18', 'Paroaria coronata_18',\n",
    "       'Calcarius ornatus_18', 'Passer montanus_18', 'Pycnonotus cafer_18',\n",
    "       'Sicalis flaveola_18', 'Estrilda astrild_18', 'Pycnonotus jocosus_18',\n",
    "       'Copsychus malabaricus_18', 'Rhynchophanes mccownii_18',\n",
    "       'Paroaria capitata_18', 'Leiothrix lutea_18',\n",
    "       'Peucedramus taeniatus_18', 'Lonchura atricapilla_18',\n",
    "       'Centronyx bairdii_18', 'Chasiempis sandwichensis_18',\n",
    "       'Euodice cantans_18', 'Vidua macroura_18', 'Horornis diphone_18',\n",
    "       'Garrulax canorus_18', 'Calcarius pictus_18', 'Zosterops simplex_18',\n",
    "       'Alauda arvensis_18', 'Oenanthe oenanthe_18',\n",
    "       'Euplectes franciscanus_18', 'Phylloscopus borealis_18',\n",
    "       'Amandava amandava_18', 'Chasiempis sclateri_18',\n",
    "       'Sporophila torqueola_18', 'Luscinia svecica_18', 'Estrilda melpoda_18',\n",
    "       'Chasiempis ibidis_18', 'Pachyramphus aglaiae_18',\n",
    "       'Plectrophenax hyperboreus_18', 'Prunella montanella_18',\n",
    "       'Spindalis zena_18', 'Tarsiger cyanurus_18', 'Coereba flaveola_18',\n",
    "       'Tiaris olivaceus_18', 'Phylloscopus fuscatus_18', 'Lanius collurio_18',\n",
    "       'Muscicapa griseisticta_18', 'Phylloscopus inornatus_18',\n",
    "       'Lanius cristatus_18', 'Acrocephalus familiaris_18',\n",
    "       'Phylloscopus trochilus_18', 'Muscicapa sibirica_18',\n",
    "       'Ficedula albicilla_18', 'Estrilda troglodytes_18',\n",
    "       'Phylloscopus collybita_18', 'Lonchura malacca_18',\n",
    "       'Saxicola maurus_18', 'Larvivora sibilans_18',\n",
    "       'Phylloscopus examinandus_18', 'Erithacus rubecula_18',\n",
    "       'Locustella lanceolata_18', 'Cyanerpes cyaneus_18',\n",
    "       'Acrocephalus schoenobaenus_18', 'Acrocephalus dumetorum_18',\n",
    "       'Locustella fluviatilis_18', 'Uraeginthus bengalus_18',\n",
    "       'Luscinia cyane_18', 'Phoenicurus phoenicurus_18',\n",
    "       'Taeniopygia guttata_18', 'Pachyramphus major_18',\n",
    "       'Oenanthe pleschanka_18'] #, 'target']\n",
    "\n",
    "pot = []\n",
    "for i in jazz:\n",
    "    model = stats.linregress(c92[i], c92['target'])\n",
    "    print(i)\n",
    "    print(\"\\n model: \", model)\n",
    "    print(\"기울기: \", model.slope)\n",
    "    print(\"절편: \", model.intercept) \n",
    "    print(\"상관계수: \", model.rvalue) \n",
    "    print(\"p값: \", model.pvalue)\n",
    "    print(\"표준오차: \", model.stderr)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    if model.pvalue < 0.05:\n",
    "        pot.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5482d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 독립선형회귀분석을 거친 경우\n",
    "lemon=[]\n",
    "for i in pot:\n",
    "    lemon.append(i.replace(' ','_').replace('-',''))\n",
    "\n",
    "    \n",
    "lemon2 = ' + '.join(lemon)\n",
    "lemon\n",
    "lemon2\n",
    "\n",
    "for i in c92.columns:\n",
    "    for j in range(0, len(pot)):\n",
    "        if i == pot[j]:\n",
    "            c92.rename(columns={i: lemon[j]}, inplace = True)\n",
    "\n",
    "c92.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f776ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ols('target ~ ' + lemon2, data=c92).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b08bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p1 = list(green_moss.index)\n",
    "#add_p1.remove('target')\n",
    "add_p1\n",
    "\n",
    "lemon2 = ' + '.join(add_p1)\n",
    "lemon2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "#green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p1 = list(green_moss.index)\n",
    "add_p1\n",
    "\n",
    "lemon2 = ' + '.join(add_p1)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p1 = list(green_moss.index)\n",
    "add_p1\n",
    "\n",
    "lemon2 = ' + '.join(add_p1)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f54b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p1 = list(green_moss.index)\n",
    "add_p1\n",
    "\n",
    "lemon2 = ' + '.join(add_p1)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb326897",
   "metadata": {},
   "source": [
    "##### 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p1 = list(green_moss.index)\n",
    "add_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32980d1d",
   "metadata": {},
   "source": [
    "#### 처음부터 다중선형회귀분석으로 직행하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45df13d",
   "metadata": {},
   "source": [
    "##### 수가 많은 종 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_copy2 = c92_18.copy()\n",
    "\n",
    "c92_copy2.columns\n",
    "\n",
    "# 2) 처음부터 다중선형회귀분석으로 직행하는 경우\n",
    "lemon=[]\n",
    "for i in c92_copy2.columns[:len(c92_copy2.columns)-1]:\n",
    "    lemon.append(i.replace(' ','_').replace('-',''))\n",
    "len(lemon)  \n",
    "\n",
    "rime = ' + '.join(lemon)\n",
    "rime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "rime = 'Harmonia_axyridis_18 + Coccinella_septempunctata_18 + Hippodamia_convergens_18 + Coelophora_maculata_18 + Cycloneda_sanguinea_18 + Propylea_quatuordecimpunctata_18 + Cycloneda_munda_18 + Psyllobora_vigintimaculata_18 + Chilocorus_stigma_18 + Olla_vnigrum_18 + Hippodamia_variegata_18 + Coccinella_californica_18 + Cycloneda_polita_18 + Cryptolaemus_montrouzieri_18 + Coccinella_trifasciata_18 + Epilachna_borealis_18 + Anatis_mali_18 + Chilocorus_cacti_18 + Brachiacantha_ursina_18 + Hippodamia_parenthesis_18 + Anatis_labiculata_18 + Mulsantina_picta_18 + Coccinella_transversoguttata_18 + Psyllobora_renifer_18 + Naemia_seriata_18 + Hippodamia_tredecimpunctata_18 + Epilachna_varivestis_18 + Coccinella_novemnotata_18 + Hippodamia_glacialis_18 + Anatis_lecontei_18 + Axion_plagiatum_18 + Calvia_quatuordecimguttata_18 + Coleomegilla_maculata_18 + Stethorus_punctillum_18 + Anatis_rathvoni_18 + Psyllobora_borealis_18 + Curinus_coeruleus_18 + Myzia_pullata_18 + Halmus_chalybeus_18 + Neoharmonia_venusta_18 + Exochomus_childreni_18 + Hippodamia_caseyi_18 + Coelophora_inaequalis_18 + Coccinella_monticola_18 + Mulsantina_hudsonica_18 + Anisosticta_bitriangularis_18 + Hyperaspis_binotata_18 + Diomus_terminatus_18 + Exochomus_quadripustulatus_18 + Hippodamia_sinuata_18 + Brumoides_septentrionis_18 + Hippodamia_quinquesignata_18 + Hyperaspis_bigeminata_18 + Paranaemia_vittigera_18 + Chilocorus_bipustulatus_18 + Rhyzobius_lophanthae_18 + Novius_cardinalis_18 + Brachiacantha_decempustulata_18 + Scymnus_loewii_18 + Scymnus_nebulosus_18 + Didion_punctatum_18 + Stethorus_punctum_18 + Myzia_interrupta_18 + Hyperaspis_trifurcata_18 + Axion_tripustulatum_18 + Epilachna_tredecimnotata_18 + Subcoccinella_vigintiquatuorpunctata_18 + Hippodamia_apicalis_18 + Hyperaspis_undulata_18 + Exochomus_aethiops_18 + Hyperaspis_lateralis_18 + Coccinella_hieroglyphica_18 + Hyperaspis_quadrioculata_18 + Microweisea_misella_18 + Exochomus_marginipennis_18 + Hippodamia_oregonensis_18 + Myzia_subvittata_18 + Brachiacantha_dentipes_18 + Psyllobora_parvinotata_18 + Nephus_flavifrons_18 + Brachiacantha_quadripunctata_18 + Hyperaspis_proba_18 + Egius_platycephalus_18 + Hyperaspis_connectens_18 + Nephus_intrusus_18 + Exochomus_fasciatus_18 + Scymnus_louisianae_18 + Coccinella_undecimpunctata_18 + Delphastus_pusillus_18 + Eremophila_alpestris_18 + Lanius_ludovicianus_18 + Plectrophenax_nivalis_18 + Phainopepla_nitens_18 + Lanius_borealis_18 + Calcarius_lapponicus_18 + Cinclus_mexicanus_18 + Lonchura_punctulata_18 + Zosterops_japonicus_18 + Centronyx_henslowii_18 + Paroaria_coronata_18 + Calcarius_ornatus_18 + Passer_montanus_18 + Pycnonotus_cafer_18 + Sicalis_flaveola_18 + Estrilda_astrild_18 + Pycnonotus_jocosus_18 + Copsychus_malabaricus_18 + Rhynchophanes_mccownii_18 + Paroaria_capitata_18 + Leiothrix_lutea_18 + Peucedramus_taeniatus_18 + Lonchura_atricapilla_18 + Centronyx_bairdii_18 + Chasiempis_sandwichensis_18 + Euodice_cantans_18 + Vidua_macroura_18 + Horornis_diphone_18 + Garrulax_canorus_18 + Calcarius_pictus_18 + Zosterops_simplex_18 + Alauda_arvensis_18 + Oenanthe_oenanthe_18 + Euplectes_franciscanus_18 + Phylloscopus_borealis_18 + Amandava_amandava_18 + Chasiempis_sclateri_18 + Sporophila_torqueola_18 + Luscinia_svecica_18 + Estrilda_melpoda_18 + Chasiempis_ibidis_18 + Pachyramphus_aglaiae_18 + Plectrophenax_hyperboreus_18 + Prunella_montanella_18 + Spindalis_zena_18 + Tarsiger_cyanurus_18 + Coereba_flaveola_18 + Tiaris_olivaceus_18 + Phylloscopus_fuscatus_18 + Lanius_collurio_18 + Muscicapa_griseisticta_18 + Phylloscopus_inornatus_18 + Lanius_cristatus_18 + Acrocephalus_familiaris_18 + Phylloscopus_trochilus_18 + Muscicapa_sibirica_18 + Ficedula_albicilla_18 + Estrilda_troglodytes_18 + Phylloscopus_collybita_18 + Lonchura_malacca_18 + Saxicola_maurus_18 + Larvivora_sibilans_18 + Phylloscopus_examinandus_18 + Erithacus_rubecula_18 + Locustella_lanceolata_18 + Cyanerpes_cyaneus_18 + Acrocephalus_schoenobaenus_18 + Acrocephalus_dumetorum_18 + Locustella_fluviatilis_18 + Uraeginthus_bengalus_18 + Luscinia_cyane_18 + Phoenicurus_phoenicurus_18 + Taeniopygia_guttata_18 + Pachyramphus_major_18 + Oenanthe_pleschanka_18'\n",
    "    \n",
    "for i in range(0, len(c92_copy2.columns[:len(c92_copy2.columns)-1])):\n",
    "    c92_copy2.rename(columns={c92_copy2.columns[i]: lemon[i]}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6df08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_copy2 = c92_copy2.fillna(0)\n",
    "c92_copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차 종다회귀분석\n",
    "res = ols('target ~ ' + rime, data=c92_copy2).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72287c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "add_p = list(green_moss.index)\n",
    "\n",
    "\n",
    "lemon2 = ' + '.join(add_p)\n",
    "lemon2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 종다회귀분석\n",
    "\n",
    "res = ols('target ~ ' + lemon2, data=c92_copy2).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p2 = list(green_moss.index)\n",
    "add_p2\n",
    "\n",
    "lemon2 = ' + '.join(add_p2)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92_copy2).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p2 = list(green_moss.index)\n",
    "add_p2\n",
    "\n",
    "lemon2 = ' + '.join(add_p2)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92_copy2).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p2 = list(green_moss.index)\n",
    "add_p2\n",
    "\n",
    "lemon2 = ' + '.join(add_p2)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더\n",
    "res = ols('target ~ ' + lemon2, data=c92_copy2).fit()\n",
    "res.summary()\n",
    "\n",
    "green_moss = pd.DataFrame(res.pvalues)\n",
    "green_moss = green_moss[green_moss[0] < 0.05]\n",
    "green_moss.drop(['Intercept'], inplace=True)\n",
    "\n",
    "add_p2 = list(green_moss.index)\n",
    "add_p2\n",
    "\n",
    "lemon2 = ' + '.join(add_p2)\n",
    "lemon2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64488269",
   "metadata": {},
   "source": [
    "#### 결과 종합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92 = c92.drop(columns = 'target')\n",
    "c92 = c92.drop(columns = 'Species_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a20cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 C9 gps 인근에서의 보고 건수(중복은 누락)\n",
    "\n",
    "# lemon = []\n",
    "# for i in c92.columns:\n",
    "#     lemon.append(i.replace(' ','_'))\n",
    "\n",
    "# for i in range(0, len(lemon)):\n",
    "#     c92.rename(columns={c92.columns[i]: lemon[i]}, inplace = True)\n",
    "    \n",
    "# dicts1 = {}\n",
    "# for i in lemon:\n",
    "#     dicts1[i] = c92[i].sum()\n",
    "    \n",
    "# dicts1 = sorted(dicts1.items(), key = lambda item: item[1], reverse = True)\n",
    "# dicts1\n",
    "\n",
    "\n",
    "\n",
    "## 각 C9 gps 인근에 있었는지 여부에 대한 체크\n",
    "\n",
    "dicts2 = {}\n",
    "for i in c92.columns:\n",
    "    dicts2[i] = len(c92[c92[i] != 0])\n",
    "    \n",
    "dicts2 = sorted(dicts2.items(), key = lambda item: item[1], reverse = True)\n",
    "dicts2\n",
    "dicts2 = dicts2[:4]\n",
    "add_f = [x[0] for x in dicts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0da5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_f2 = []\n",
    "\n",
    "for i in add_f:\n",
    "    add_f2.append(i.replace(' ', '_'))\n",
    "    \n",
    "add_f = add_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC = list(set(add_p1 + add_f))\n",
    "DJ = list(set(add_p2 + add_f))\n",
    "\n",
    "len(MC)\n",
    "len(DJ)\n",
    "\n",
    "len(MC)\n",
    "len(DJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e067396",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC\n",
    "DJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad811790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c92_copy2['risk_degree2'] = c92_backup['risk_degree2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92sop1_x = c92_copy2[MC]\n",
    "c92sop2_x = c92_copy2[DJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf147c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c92sop1_x = c92sr2_x[['Coccinella septempunctata', 'Harmonia axyridis', 'Cryptolaemus montrouzieri', 'Axion plagiatum', 'Coccinella transversoguttata', 'Hippodamia convergens', 'Adalia bipunctata', 'Cycloneda sanguinea', 'Coccinella californica', 'Hippodamia parenthesis', 'Hyperaspis lateralis']]\n",
    "\n",
    "# c92sop2_x = c92sr2_x[['Cryptolaemus montrouzieri', 'Axion plagiatum', 'Coccinella transversoguttata', 'Hippodamia convergens', 'Adalia bipunctata', 'Cycloneda sanguinea', 'Coccinella californica', 'Hippodamia parenthesis', 'Hyperaspis lateralis']]\n",
    "\n",
    "# c92sopr_x = c92sr2_x[['Cryptolaemus montrouzieri', 'Axion plagiatum', 'Coccinella transversoguttata', 'Hippodamia convergens', 'Adalia bipunctata', 'Cycloneda sanguinea', 'Coccinella californica', 'Hippodamia parenthesis', 'Hyperaspis lateralis', 'risk_degree2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560d910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e42ecc2f",
   "metadata": {},
   "source": [
    "#### 다중공산성\n",
    "- 10 이하, 엄격할 경우 5 이하"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5be0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.light_palette(\"darkgray\", as_cmap=True)\n",
    "sns.heatmap(c92sop1_x.corr(), annot=True, cmap=cmap)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cmap = sns.light_palette(\"darkgray\", as_cmap=True)\n",
    "sns.heatmap(c92sop2_x.corr(), annot=True, cmap=cmap)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_copy2[MC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b36349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axion plagiatum~@@@Hippodamia convergens~Cycloneda sanguinea\n",
    "# @@@Hippodamia parenthesis\n",
    "# Coccinella transversoguttata\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "# 골라서 넣기\n",
    "X = c92_copy2[MC]\n",
    "#X = c92_copy2[DJ]\n",
    "\n",
    "\n",
    "X.columns\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif\n",
    "\n",
    "try:\n",
    "    vif.loc[vif['VIF Factor'] < 10]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Cryptolaemus montrouzieri\n",
    "# Axion plagiatum~@@@Hippodamia convergens~Cycloneda sanguinea\n",
    "\n",
    "# @@@Hippodamia parenthesis\n",
    "## Coccinella transversoguttata\n",
    "\n",
    "\n",
    "# sangui ~ C7#, conver, plagiatum, axyridis\n",
    "# C7 ~ sang, conv, axy, plagia\n",
    "\n",
    "# tran ~ parenthesis # paren ~ transvers,\n",
    "\n",
    "# conv ~ sang, c7, plagiatum, axyridis \n",
    "# axion, sangui, c7, conv, axy\n",
    "# axy ~ sang, c7, conv, axion, \n",
    "\n",
    "# lat ~ punctill, scymus caurinus\n",
    "# punc ~ lat, caurinus\n",
    "# scymnus ~ transvers, lateralis, punctillum\n",
    "\n",
    "\n",
    "# Mc의 살릴 목록\n",
    "# Hippodamia_convergens\n",
    "# Hippodamia_parenthesis\n",
    "# Scymnus_caurinus\n",
    "\n",
    "\n",
    "\n",
    "# ----------\n",
    "\n",
    "# MCr 목록\n",
    "# Sangui ~ cone, plaㅎ\n",
    "# Trans ~ parenthesis\n",
    "# Lat - ounce, cairn\n",
    "# Punc - lat, caurin\n",
    "# Cons - Sangui, plag\n",
    "# Parent - trans, \n",
    "# Axion - Sangui, cone, \n",
    "# Cairn - lat, punc\n",
    "\n",
    "for i in vif.index:\n",
    "    if vif['VIF Factor'][i] > 10:\n",
    "        vif.drop(index = i)\n",
    "        \n",
    "geek = vif.features.tolist()\n",
    "MC = geek.copy()\n",
    "#DJ = geek.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78330529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axion plagiatum~@@@Hippodamia convergens~Cycloneda sanguinea\n",
    "# @@@Hippodamia parenthesis\n",
    "# Coccinella transversoguttata\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "# 골라서 넣기\n",
    "# X = c92_copy2[MC]\n",
    "X = c92_copy2[DJ]\n",
    "\n",
    "\n",
    "X.columns\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif\n",
    "\n",
    "try:\n",
    "    vif.loc[vif['VIF Factor'] < 10]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Cryptolaemus montrouzieri\n",
    "# Axion plagiatum~@@@Hippodamia convergens~Cycloneda sanguinea\n",
    "\n",
    "# @@@Hippodamia parenthesis\n",
    "## Coccinella transversoguttata\n",
    "\n",
    "\n",
    "# sangui ~ C7#, conver, plagiatum, axyridis\n",
    "# C7 ~ sang, conv, axy, plagia\n",
    "\n",
    "# tran ~ parenthesis # paren ~ transvers,\n",
    "\n",
    "# conv ~ sang, c7, plagiatum, axyridis \n",
    "# axion, sangui, c7, conv, axy\n",
    "# axy ~ sang, c7, conv, axion, \n",
    "\n",
    "# lat ~ punctill, scymus caurinus\n",
    "# punc ~ lat, caurinus\n",
    "# scymnus ~ transvers, lateralis, punctillum\n",
    "\n",
    "\n",
    "# Mc의 살릴 목록\n",
    "# Hippodamia_convergens\n",
    "# Hippodamia_parenthesis\n",
    "# Scymnus_caurinus\n",
    "\n",
    "\n",
    "\n",
    "# ----------\n",
    "\n",
    "# MCr 목록\n",
    "# Sangui ~ cone, plaㅎ\n",
    "# Trans ~ parenthesis\n",
    "# Lat - ounce, cairn\n",
    "# Punc - lat, caurin\n",
    "# Cons - Sangui, plag\n",
    "# Parent - trans, \n",
    "# Axion - Sangui, cone, \n",
    "# Cairn - lat, punc\n",
    "\n",
    "for i in vif.index:\n",
    "    if vif['VIF Factor'][i] > 10:\n",
    "        vif.drop(index = i)\n",
    "        \n",
    "geek = vif.features.tolist()\n",
    "#MC = geek.copy()\n",
    "DJ = geek.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38849480",
   "metadata": {},
   "source": [
    "## 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a430f",
   "metadata": {},
   "source": [
    "### 압축 전(변수 10개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_copy2[MC]\n",
    "KVIM = c92_copy2[DJ]\n",
    "# KVIM.drop(columns = ['Lonchura_cucullata_1', 'Locustella_ochotensis_1'], inplace=True)\n",
    "\n",
    "BBOY=['Harmonia_axyridis_18', 'Coccinella_septempunctata_18', 'Hippodamia_convergens_18', 'Eremophila_alpestris_18']\n",
    "\n",
    "TAGGER1 = ['Anatis_labiculata_18', 'Hippodamia_apicalis_18', 'Microweisea_misella_18', 'Delphastus_pusillus_18', 'Amphispiza_bilineata_18']\n",
    "\n",
    "TAGGER2 = list(set(TAGGER1 + DJ))\n",
    "\n",
    "TAGGER3 = ['Delphastus_pusillus_18',\n",
    " 'Plectrophenax_nivalis_18',\n",
    " 'Hippodamia_convergens_18',\n",
    " 'Pipilo_chlorurus_18',\n",
    " 'Artemisiospiza_belli_18',\n",
    " 'Phainopepla_nitens_18',\n",
    " 'Myzia_interrupta_18',\n",
    " 'Hippodamia_quinquesignata_18',\n",
    " 'Eremophila_alpestris_18',\n",
    " 'Hippodamia_caseyi_18',\n",
    " 'Harmonia_axyridis_18',\n",
    " 'Coccinella_monticola_18',\n",
    " 'Subcoccinella_vigintiquatuorpunctata_18',\n",
    " 'Melozone_crissalis_18',\n",
    " 'Melozone_aberti_18',\n",
    " 'Microweisea_misella_18',\n",
    " 'Hyperaspis_quadrioculata_18',\n",
    " 'Amphispiza_bilineata_18',\n",
    " 'Coccinella_septempunctata_18',\n",
    " 'Hippodamia_glacialis_18',\n",
    " 'Exochomus_aethiops_18',\n",
    " 'Lonchura_punctulata_18']\n",
    "\n",
    "\n",
    "c92_copy2[BBOY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "DJ\n",
    "MC\n",
    "BBOY\n",
    "TAGGER2\n",
    "\n",
    "len(DJ)\n",
    "len(MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadbe6ef",
   "metadata": {},
   "source": [
    "################ 임시로 해놓은 필드임. 추후 꼭 삭제하기. 아니면 변수 구성이 고정되어버림.\n",
    "\n",
    "\n",
    "\n",
    "TAGGER = ['Coelophora_maculata_18',\n",
    " 'Coccinella_californica_18',\n",
    " 'Adalia_bipunctata_18',\n",
    " 'Eremophila_alpestris_18',\n",
    " 'Zonotrichia_leucophrys_18',\n",
    " 'Spizella_passerina_18']\n",
    "\n",
    "\n",
    "MC = ['Adalia_bipunctata_18',\n",
    " 'Coccinella_californica_18',\n",
    " 'Harmonia_axyridis_18',\n",
    " 'Zonotrichia_leucophrys_18',\n",
    " 'Hippodamia_convergens_18',\n",
    " 'Coccinella_septempunctata_18',\n",
    " 'Spizella_passerina_18',\n",
    " 'Coelophora_maculata_18',\n",
    " 'Eremophila_alpestris_18']\n",
    "\n",
    "DJ = ['Pipilo_chlorurus_18',\n",
    " 'Coccinella_transversoguttata_18',\n",
    " 'Hippodamia_convergens_18',\n",
    " 'Lonchura_punctulata_18',\n",
    " 'Plectrophenax_nivalis_18',\n",
    " 'Exochomus_aethiops_18',\n",
    " 'Hippodamia_apicalis_18',\n",
    " 'Hippodamia_glacialis_18',\n",
    " 'Artemisiospiza_belli_18',\n",
    " 'Harmonia_axyridis_18',\n",
    " 'Subcoccinella_vigintiquatuorpunctata_18',\n",
    " 'Phainopepla_nitens_18',\n",
    " 'Coccinella_monticola_18',\n",
    " 'Myzia_interrupta_18',\n",
    " 'Melozone_crissalis_18',\n",
    " 'Coccinella_septempunctata_18',\n",
    " 'Melozone_aberti_18',\n",
    " 'Eremophila_alpestris_18',\n",
    " 'Hippodamia_quinquesignata_18',\n",
    " 'Zonotrichia_leucophrys_18',\n",
    " 'Hyperaspis_quadrioculata_18',\n",
    " 'Hippodamia_caseyi_18']\n",
    "\n",
    "\n",
    "BBOY=['Harmonia_axyridis_18', 'Coccinella_septempunctata_18', 'Coelophora_maculata_18', 'Hippodamia_convergens_18', 'Coccinella_transversoguttata_18', 'Eremophila_alpestris_18', 'Zonotrichia_leucophrys_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c92_copy2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEATMKR = ['Harmonia_axyridis_18', 'Coccinella_septempunctata_18',\n",
    "       'Hippodamia_convergens_18', 'Coelophora_maculata_18',\n",
    "       'Cycloneda_sanguinea_18', 'Propylea_quatuordecimpunctata_18',\n",
    "       'Cycloneda_munda_18', 'Psyllobora_vigintimaculata_18',\n",
    "       'Chilocorus_stigma_18', 'Olla_vnigrum_18', 'Hippodamia_variegata_18',\n",
    "       'Coccinella_californica_18', 'Cycloneda_polita_18',\n",
    "       'Cryptolaemus_montrouzieri_18', 'Coccinella_trifasciata_18',\n",
    "       'Epilachna_borealis_18', 'Anatis_mali_18', 'Chilocorus_cacti_18',\n",
    "       'Brachiacantha_ursina_18', 'Hippodamia_parenthesis_18',\n",
    "       'Anatis_labiculata_18', 'Mulsantina_picta_18',\n",
    "       'Coccinella_transversoguttata_18', 'Psyllobora_renifer_18',\n",
    "       'Naemia_seriata_18', 'Hippodamia_tredecimpunctata_18',\n",
    "       'Epilachna_varivestis_18', 'Coccinella_novemnotata_18',\n",
    "       'Hippodamia_glacialis_18', 'Anatis_lecontei_18', 'Axion_plagiatum_18',\n",
    "       'Calvia_quatuordecimguttata_18', 'Coleomegilla_maculata_18',\n",
    "       'Stethorus_punctillum_18', 'Anatis_rathvoni_18',\n",
    "       'Psyllobora_borealis_18', 'Curinus_coeruleus_18', 'Myzia_pullata_18',\n",
    "       'Halmus_chalybeus_18', 'Neoharmonia_venusta_18',\n",
    "       'Exochomus_childreni_18', 'Hippodamia_caseyi_18',\n",
    "       'Coelophora_inaequalis_18', 'Coccinella_monticola_18',\n",
    "       'Mulsantina_hudsonica_18', 'Anisosticta_bitriangularis_18',\n",
    "       'Hyperaspis_binotata_18', 'Diomus_terminatus_18',\n",
    "       'Exochomus_quadripustulatus_18', 'Hippodamia_sinuata_18',\n",
    "       'Brumoides_septentrionis_18', 'Hippodamia_quinquesignata_18',\n",
    "       'Hyperaspis_bigeminata_18', 'Paranaemia_vittigera_18',\n",
    "       'Chilocorus_bipustulatus_18', 'Rhyzobius_lophanthae_18',\n",
    "       'Novius_cardinalis_18', 'Brachiacantha_decempustulata_18',\n",
    "       'Scymnus_loewii_18', 'Scymnus_nebulosus_18', 'Didion_punctatum_18',\n",
    "       'Stethorus_punctum_18', 'Myzia_interrupta_18',\n",
    "       'Hyperaspis_trifurcata_18', 'Axion_tripustulatum_18',\n",
    "       'Epilachna_tredecimnotata_18',\n",
    "       'Subcoccinella_vigintiquatuorpunctata_18', 'Hippodamia_apicalis_18',\n",
    "       'Hyperaspis_undulata_18', 'Exochomus_aethiops_18',\n",
    "       'Hyperaspis_lateralis_18', 'Coccinella_hieroglyphica_18',\n",
    "       'Hyperaspis_quadrioculata_18', 'Microweisea_misella_18',\n",
    "       'Exochomus_marginipennis_18', 'Hippodamia_oregonensis_18',\n",
    "       'Myzia_subvittata_18', 'Brachiacantha_dentipes_18',\n",
    "       'Psyllobora_parvinotata_18', 'Nephus_flavifrons_18',\n",
    "       'Brachiacantha_quadripunctata_18', 'Hyperaspis_proba_18',\n",
    "       'Egius_platycephalus_18', 'Hyperaspis_connectens_18',\n",
    "       'Nephus_intrusus_18', 'Exochomus_fasciatus_18', 'Scymnus_louisianae_18',\n",
    "       'Coccinella_undecimpunctata_18', 'Delphastus_pusillus_18',\n",
    "       'Eremophila_alpestris_18', 'Lanius_ludovicianus_18',\n",
    "       'Plectrophenax_nivalis_18', 'Phainopepla_nitens_18',\n",
    "       'Lanius_borealis_18', 'Calcarius_lapponicus_18', 'Cinclus_mexicanus_18',\n",
    "       'Lonchura_punctulata_18', 'Zosterops_japonicus_18',\n",
    "       'Centronyx_henslowii_18', 'Paroaria_coronata_18',\n",
    "       'Calcarius_ornatus_18', 'Passer_montanus_18', 'Pycnonotus_cafer_18',\n",
    "       'Sicalis_flaveola_18', 'Estrilda_astrild_18', 'Pycnonotus_jocosus_18',\n",
    "       'Copsychus_malabaricus_18', 'Rhynchophanes_mccownii_18',\n",
    "       'Paroaria_capitata_18', 'Leiothrix_lutea_18',\n",
    "       'Peucedramus_taeniatus_18', 'Lonchura_atricapilla_18',\n",
    "       'Centronyx_bairdii_18', 'Chasiempis_sandwichensis_18',\n",
    "       'Euodice_cantans_18', 'Vidua_macroura_18', 'Horornis_diphone_18',\n",
    "       'Garrulax_canorus_18', 'Calcarius_pictus_18', 'Zosterops_simplex_18',\n",
    "       'Alauda_arvensis_18', 'Oenanthe_oenanthe_18',\n",
    "       'Euplectes_franciscanus_18', 'Phylloscopus_borealis_18',\n",
    "       'Amandava_amandava_18', 'Chasiempis_sclateri_18',\n",
    "       'Sporophila_torqueola_18', 'Luscinia_svecica_18', 'Estrilda_melpoda_18',\n",
    "       'Chasiempis_ibidis_18', 'Pachyramphus_aglaiae_18',\n",
    "       'Plectrophenax_hyperboreus_18', 'Prunella_montanella_18',\n",
    "       'Spindalis_zena_18', 'Tarsiger_cyanurus_18', 'Coereba_flaveola_18',\n",
    "       'Tiaris_olivaceus_18', 'Phylloscopus_fuscatus_18', 'Lanius_collurio_18',\n",
    "       'Muscicapa_griseisticta_18', 'Phylloscopus_inornatus_18',\n",
    "       'Lanius_cristatus_18', 'Acrocephalus_familiaris_18',\n",
    "       'Phylloscopus_trochilus_18', 'Muscicapa_sibirica_18',\n",
    "       'Ficedula_albicilla_18', 'Estrilda_troglodytes_18',\n",
    "       'Phylloscopus_collybita_18', 'Lonchura_malacca_18',\n",
    "       'Saxicola_maurus_18', 'Larvivora_sibilans_18',\n",
    "       'Phylloscopus_examinandus_18', 'Erithacus_rubecula_18',\n",
    "       'Locustella_lanceolata_18', 'Cyanerpes_cyaneus_18',\n",
    "       'Acrocephalus_schoenobaenus_18', 'Acrocephalus_dumetorum_18',\n",
    "       'Locustella_fluviatilis_18', 'Uraeginthus_bengalus_18',\n",
    "       'Luscinia_cyane_18', 'Phoenicurus_phoenicurus_18',\n",
    "       'Taeniopygia_guttata_18', 'Pachyramphus_major_18',\n",
    "       'Oenanthe_pleschanka_18']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BEATMKR_SE = ['Harmonia_axyridis_18', #'Coccinella_septempunctata_18',\n",
    "       'Hippodamia_convergens_18', 'Coelophora_maculata_18',\n",
    "       'Cycloneda_sanguinea_18', 'Propylea_quatuordecimpunctata_18',\n",
    "       'Cycloneda_munda_18', 'Psyllobora_vigintimaculata_18',\n",
    "       'Chilocorus_stigma_18', 'Olla_vnigrum_18', 'Hippodamia_variegata_18',\n",
    "       'Coccinella_californica_18', 'Cycloneda_polita_18',\n",
    "       'Cryptolaemus_montrouzieri_18', 'Coccinella_trifasciata_18',\n",
    "       'Epilachna_borealis_18', 'Anatis_mali_18', 'Chilocorus_cacti_18',\n",
    "       'Brachiacantha_ursina_18', 'Hippodamia_parenthesis_18',\n",
    "       'Anatis_labiculata_18', 'Mulsantina_picta_18',\n",
    "       'Coccinella_transversoguttata_18', 'Psyllobora_renifer_18',\n",
    "       'Naemia_seriata_18', 'Hippodamia_tredecimpunctata_18',\n",
    "       'Epilachna_varivestis_18', 'Coccinella_novemnotata_18',\n",
    "       'Hippodamia_glacialis_18', 'Anatis_lecontei_18', 'Axion_plagiatum_18',\n",
    "       'Calvia_quatuordecimguttata_18', 'Coleomegilla_maculata_18',\n",
    "       'Stethorus_punctillum_18', 'Anatis_rathvoni_18',\n",
    "       'Psyllobora_borealis_18', 'Curinus_coeruleus_18', 'Myzia_pullata_18',\n",
    "       'Halmus_chalybeus_18', 'Neoharmonia_venusta_18',\n",
    "       'Exochomus_childreni_18', 'Hippodamia_caseyi_18',\n",
    "       'Coelophora_inaequalis_18', 'Coccinella_monticola_18',\n",
    "       'Mulsantina_hudsonica_18', 'Anisosticta_bitriangularis_18',\n",
    "       'Hyperaspis_binotata_18', 'Diomus_terminatus_18',\n",
    "       'Exochomus_quadripustulatus_18', 'Hippodamia_sinuata_18',\n",
    "       'Brumoides_septentrionis_18', 'Hippodamia_quinquesignata_18',\n",
    "       'Hyperaspis_bigeminata_18', 'Paranaemia_vittigera_18',\n",
    "       'Chilocorus_bipustulatus_18', 'Rhyzobius_lophanthae_18',\n",
    "       'Novius_cardinalis_18', 'Brachiacantha_decempustulata_18',\n",
    "       'Scymnus_loewii_18', 'Scymnus_nebulosus_18', 'Didion_punctatum_18',\n",
    "       'Stethorus_punctum_18', 'Myzia_interrupta_18',\n",
    "       'Hyperaspis_trifurcata_18', 'Axion_tripustulatum_18',\n",
    "       'Epilachna_tredecimnotata_18',\n",
    "       'Subcoccinella_vigintiquatuorpunctata_18', 'Hippodamia_apicalis_18',\n",
    "       'Hyperaspis_undulata_18', 'Exochomus_aethiops_18',\n",
    "       'Hyperaspis_lateralis_18', 'Coccinella_hieroglyphica_18',\n",
    "       'Hyperaspis_quadrioculata_18', 'Microweisea_misella_18',\n",
    "       'Exochomus_marginipennis_18', 'Hippodamia_oregonensis_18',\n",
    "       'Myzia_subvittata_18', 'Brachiacantha_dentipes_18',\n",
    "       'Psyllobora_parvinotata_18', 'Nephus_flavifrons_18',\n",
    "       'Brachiacantha_quadripunctata_18', 'Hyperaspis_proba_18',\n",
    "       'Egius_platycephalus_18', 'Hyperaspis_connectens_18',\n",
    "       'Nephus_intrusus_18', 'Exochomus_fasciatus_18', 'Scymnus_louisianae_18',\n",
    "       'Coccinella_undecimpunctata_18', 'Delphastus_pusillus_18',\n",
    "       'Eremophila_alpestris_18', 'Lanius_ludovicianus_18',\n",
    "       'Plectrophenax_nivalis_18', 'Phainopepla_nitens_18',\n",
    "       'Lanius_borealis_18', 'Calcarius_lapponicus_18', 'Cinclus_mexicanus_18',\n",
    "       'Lonchura_punctulata_18', 'Zosterops_japonicus_18',\n",
    "       'Centronyx_henslowii_18', 'Paroaria_coronata_18',\n",
    "       'Calcarius_ornatus_18', 'Passer_montanus_18', 'Pycnonotus_cafer_18',\n",
    "       'Sicalis_flaveola_18', 'Estrilda_astrild_18', 'Pycnonotus_jocosus_18',\n",
    "       'Copsychus_malabaricus_18', 'Rhynchophanes_mccownii_18',\n",
    "       'Paroaria_capitata_18', 'Leiothrix_lutea_18',\n",
    "       'Peucedramus_taeniatus_18', 'Lonchura_atricapilla_18',\n",
    "       'Centronyx_bairdii_18', 'Chasiempis_sandwichensis_18',\n",
    "       'Euodice_cantans_18', 'Vidua_macroura_18', 'Horornis_diphone_18',\n",
    "       'Garrulax_canorus_18', 'Calcarius_pictus_18', 'Zosterops_simplex_18',\n",
    "       'Alauda_arvensis_18', 'Oenanthe_oenanthe_18',\n",
    "       'Euplectes_franciscanus_18', 'Phylloscopus_borealis_18',\n",
    "       'Amandava_amandava_18', 'Chasiempis_sclateri_18',\n",
    "       'Sporophila_torqueola_18', 'Luscinia_svecica_18', 'Estrilda_melpoda_18',\n",
    "       'Chasiempis_ibidis_18', 'Pachyramphus_aglaiae_18',\n",
    "       'Plectrophenax_hyperboreus_18', 'Prunella_montanella_18',\n",
    "       'Spindalis_zena_18', 'Tarsiger_cyanurus_18', 'Coereba_flaveola_18',\n",
    "       'Tiaris_olivaceus_18', 'Phylloscopus_fuscatus_18', 'Lanius_collurio_18',\n",
    "       'Muscicapa_griseisticta_18', 'Phylloscopus_inornatus_18',\n",
    "       'Lanius_cristatus_18', 'Acrocephalus_familiaris_18',\n",
    "       'Phylloscopus_trochilus_18', 'Muscicapa_sibirica_18',\n",
    "       'Ficedula_albicilla_18', 'Estrilda_troglodytes_18',\n",
    "       'Phylloscopus_collybita_18', 'Lonchura_malacca_18',\n",
    "       'Saxicola_maurus_18', 'Larvivora_sibilans_18',\n",
    "       'Phylloscopus_examinandus_18', 'Erithacus_rubecula_18',\n",
    "       'Locustella_lanceolata_18', 'Cyanerpes_cyaneus_18',\n",
    "       'Acrocephalus_schoenobaenus_18', 'Acrocephalus_dumetorum_18',\n",
    "       'Locustella_fluviatilis_18', 'Uraeginthus_bengalus_18',\n",
    "       'Luscinia_cyane_18', 'Phoenicurus_phoenicurus_18',\n",
    "       'Taeniopygia_guttata_18', 'Pachyramphus_major_18',\n",
    "       'Oenanthe_pleschanka_18']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BEATMKR_CE = ['Harmonia_axyridis_18', 'Coccinella_septempunctata_18',\n",
    "       'Coelophora_maculata_18', # 'Hippodamia_convergens_18',\n",
    "       'Cycloneda_sanguinea_18', 'Propylea_quatuordecimpunctata_18',\n",
    "       'Cycloneda_munda_18', 'Psyllobora_vigintimaculata_18',\n",
    "       'Chilocorus_stigma_18', 'Olla_vnigrum_18', 'Hippodamia_variegata_18',\n",
    "       'Coccinella_californica_18', 'Cycloneda_polita_18',\n",
    "       'Cryptolaemus_montrouzieri_18', 'Coccinella_trifasciata_18',\n",
    "       'Epilachna_borealis_18', 'Anatis_mali_18', 'Chilocorus_cacti_18',\n",
    "       'Brachiacantha_ursina_18', 'Hippodamia_parenthesis_18',\n",
    "       'Anatis_labiculata_18', 'Mulsantina_picta_18',\n",
    "       'Coccinella_transversoguttata_18', 'Psyllobora_renifer_18',\n",
    "       'Naemia_seriata_18', 'Hippodamia_tredecimpunctata_18',\n",
    "       'Epilachna_varivestis_18', 'Coccinella_novemnotata_18',\n",
    "       'Hippodamia_glacialis_18', 'Anatis_lecontei_18', 'Axion_plagiatum_18',\n",
    "       'Calvia_quatuordecimguttata_18', 'Coleomegilla_maculata_18',\n",
    "       'Stethorus_punctillum_18', 'Anatis_rathvoni_18',\n",
    "       'Psyllobora_borealis_18', 'Curinus_coeruleus_18', 'Myzia_pullata_18',\n",
    "       'Halmus_chalybeus_18', 'Neoharmonia_venusta_18',\n",
    "       'Exochomus_childreni_18', 'Hippodamia_caseyi_18',\n",
    "       'Coelophora_inaequalis_18', 'Coccinella_monticola_18',\n",
    "       'Mulsantina_hudsonica_18', 'Anisosticta_bitriangularis_18',\n",
    "       'Hyperaspis_binotata_18', 'Diomus_terminatus_18',\n",
    "       'Exochomus_quadripustulatus_18', 'Hippodamia_sinuata_18',\n",
    "       'Brumoides_septentrionis_18', 'Hippodamia_quinquesignata_18',\n",
    "       'Hyperaspis_bigeminata_18', 'Paranaemia_vittigera_18',\n",
    "       'Chilocorus_bipustulatus_18', 'Rhyzobius_lophanthae_18',\n",
    "       'Novius_cardinalis_18', 'Brachiacantha_decempustulata_18',\n",
    "       'Scymnus_loewii_18', 'Scymnus_nebulosus_18', 'Didion_punctatum_18',\n",
    "       'Stethorus_punctum_18', 'Myzia_interrupta_18',\n",
    "       'Hyperaspis_trifurcata_18', 'Axion_tripustulatum_18',\n",
    "       'Epilachna_tredecimnotata_18',\n",
    "       'Subcoccinella_vigintiquatuorpunctata_18', 'Hippodamia_apicalis_18',\n",
    "       'Hyperaspis_undulata_18', 'Exochomus_aethiops_18',\n",
    "       'Hyperaspis_lateralis_18', 'Coccinella_hieroglyphica_18',\n",
    "       'Hyperaspis_quadrioculata_18', 'Microweisea_misella_18',\n",
    "       'Exochomus_marginipennis_18', 'Hippodamia_oregonensis_18',\n",
    "       'Myzia_subvittata_18', 'Brachiacantha_dentipes_18',\n",
    "       'Psyllobora_parvinotata_18', 'Nephus_flavifrons_18',\n",
    "       'Brachiacantha_quadripunctata_18', 'Hyperaspis_proba_18',\n",
    "       'Egius_platycephalus_18', 'Hyperaspis_connectens_18',\n",
    "       'Nephus_intrusus_18', 'Exochomus_fasciatus_18', 'Scymnus_louisianae_18',\n",
    "       'Coccinella_undecimpunctata_18', 'Delphastus_pusillus_18',\n",
    "       'Eremophila_alpestris_18', 'Lanius_ludovicianus_18',\n",
    "       'Plectrophenax_nivalis_18', 'Phainopepla_nitens_18',\n",
    "       'Lanius_borealis_18', 'Calcarius_lapponicus_18', 'Cinclus_mexicanus_18',\n",
    "       'Lonchura_punctulata_18', 'Zosterops_japonicus_18',\n",
    "       'Centronyx_henslowii_18', 'Paroaria_coronata_18',\n",
    "       'Calcarius_ornatus_18', 'Passer_montanus_18', 'Pycnonotus_cafer_18',\n",
    "       'Sicalis_flaveola_18', 'Estrilda_astrild_18', 'Pycnonotus_jocosus_18',\n",
    "       'Copsychus_malabaricus_18', 'Rhynchophanes_mccownii_18',\n",
    "       'Paroaria_capitata_18', 'Leiothrix_lutea_18',\n",
    "       'Peucedramus_taeniatus_18', 'Lonchura_atricapilla_18',\n",
    "       'Centronyx_bairdii_18', 'Chasiempis_sandwichensis_18',\n",
    "       'Euodice_cantans_18', 'Vidua_macroura_18', 'Horornis_diphone_18',\n",
    "       'Garrulax_canorus_18', 'Calcarius_pictus_18', 'Zosterops_simplex_18',\n",
    "       'Alauda_arvensis_18', 'Oenanthe_oenanthe_18',\n",
    "       'Euplectes_franciscanus_18', 'Phylloscopus_borealis_18',\n",
    "       'Amandava_amandava_18', 'Chasiempis_sclateri_18',\n",
    "       'Sporophila_torqueola_18', 'Luscinia_svecica_18', 'Estrilda_melpoda_18',\n",
    "       'Chasiempis_ibidis_18', 'Pachyramphus_aglaiae_18',\n",
    "       'Plectrophenax_hyperboreus_18', 'Prunella_montanella_18',\n",
    "       'Spindalis_zena_18', 'Tarsiger_cyanurus_18', 'Coereba_flaveola_18',\n",
    "       'Tiaris_olivaceus_18', 'Phylloscopus_fuscatus_18', 'Lanius_collurio_18',\n",
    "       'Muscicapa_griseisticta_18', 'Phylloscopus_inornatus_18',\n",
    "       'Lanius_cristatus_18', 'Acrocephalus_familiaris_18',\n",
    "       'Phylloscopus_trochilus_18', 'Muscicapa_sibirica_18',\n",
    "       'Ficedula_albicilla_18', 'Estrilda_troglodytes_18',\n",
    "       'Phylloscopus_collybita_18', 'Lonchura_malacca_18',\n",
    "       'Saxicola_maurus_18', 'Larvivora_sibilans_18',\n",
    "       'Phylloscopus_examinandus_18', 'Erithacus_rubecula_18',\n",
    "       'Locustella_lanceolata_18', 'Cyanerpes_cyaneus_18',\n",
    "       'Acrocephalus_schoenobaenus_18', 'Acrocephalus_dumetorum_18',\n",
    "       'Locustella_fluviatilis_18', 'Uraeginthus_bengalus_18',\n",
    "       'Luscinia_cyane_18', 'Phoenicurus_phoenicurus_18',\n",
    "       'Taeniopygia_guttata_18', 'Pachyramphus_major_18',\n",
    "       'Oenanthe_pleschanka_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c92_copy2.index:\n",
    "    if c92_copy2.target[i] != 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef978b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX = c92_copy2[c92_copy2.Species_18 != 'Hippodamia parenthesis'].reset_index(drop = True)\n",
    "sample = BOX[1438:].sample(n=1438, random_state = 3)\n",
    "c92_copy22 = pd.concat([BOX[:1438], sample])\n",
    "\n",
    "BOX[:1438].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb510639",
   "metadata": {},
   "source": [
    "## check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PTYPE = ['Hippodamia_convergens_18',\n",
    "'Lanius_borealis_18',\n",
    "'Coccinella_septempunctata_18',\n",
    "'Lanius_ludovicianus_18',\n",
    "'Coelophora_maculata_18',\n",
    "'Cycloneda_polita_18',\n",
    "'Cinclus_mexicanus_18',\n",
    "'Harmonia_axyridis_18',\n",
    "'Eremophila_alpestris_18',\n",
    "'Anatis_mali_18',\n",
    "'Hippodamia_tredecimpunctata_18',\n",
    "'Coccinella_trifasciata_18',\n",
    "'Anatis_lecontei_18',\n",
    "'Phainopepla_nitens_18',\n",
    "'Plectrophenax_nivalis_18',\n",
    "# 'Chilocorus_bipustulatus_18',\n",
    "# 'Chilocorus_stigma_18',\n",
    "# 'Mulsantina_hudsonica_18',\n",
    "# 'Calcarius_lapponicus_18',\n",
    "# 'Propylea_quatuordecimpunctata_18',\n",
    "# 'Axion_plagiatum_18',\n",
    "# 'Hippodamia_variegata_18',\n",
    "# 'Coccinella_transversoguttata_18',\n",
    "# 'Lonchura_punctulata_18',\n",
    "# 'Cryptolaemus_montrouzieri_18',\n",
    "# 'Centronyx_henslowii_18',\n",
    "# 'Hippodamia_parenthesis_18',\n",
    "# 'Rhyzobius_lophanthae_18',\n",
    "# 'Hippodamia_apicalis_18'\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PTYPE = ['Lanius_borealis_18',\n",
    "'Harmonia_axyridis_18',\n",
    "'Cinclus_mexicanus_18',\n",
    "'Coccinella_septempunctata_18',\n",
    "'Coelophora_maculata_18',\n",
    "'Cycloneda_polita_18',\n",
    "'Eremophila_alpestris_18',\n",
    "'Hippodamia_convergens_18',\n",
    "'Anatis_mali_18',\n",
    "'Hippodamia_tredecimpunctata_18',\n",
    "\"Psyllobora_vigintimaculata_18\",\n",
    "'Coccinella_trifasciata_18',\n",
    "'Phainopepla_nitens_18',\n",
    "'Hippodamia_variegata_18',\n",
    "'Olla_vnigrum_18',\n",
    "'Centronyx_henslowii_18',\n",
    "'Coccinella_novemnotata_18',\n",
    "'Chilocorus_stigma_18',\n",
    "'Mulsantina_hudsonica_18'] # Absence 3종 + log 버전\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f8c155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InteractiveShell.ast_node_interactivity=\"all\"\n",
    "InteractiveShell.ast_node_interactivity=\"last_expr\"\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b4b5c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자입력: 1 = C. nov. // 2 = C. trans // 3 = A. bipunc1\n"
     ]
    }
   ],
   "source": [
    "no = int(input('숫자입력: 1 = C. nov. // 2 = C. trans // 3 = A. bipunc // 4 = H. paren'))\n",
    "\n",
    "if no == 1:\n",
    "    target_species = 'Coccinella novemnotata'\n",
    "    quiz = 324\n",
    "    \n",
    "elif no == 2:\n",
    "    target_species = 'Coccinella transversoguttata'\n",
    "    quiz = 510\n",
    "    \n",
    "elif no == 3:\n",
    "    target_species = 'Adalia bipunctata'\n",
    "    quiz = 1438\n",
    "    \n",
    "elif no == 4:\n",
    "    target_species = 'Hippodamia parenthesis'\n",
    "    quiz = 759 #742\n",
    "\n",
    "    \n",
    "ratio = int(input('삭제할 비율 입력 '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b04794",
   "metadata": {},
   "source": [
    "# 머신러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "040b0057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<<<<주요종만sopr>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:05<09:44,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:12<09:55,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:20<11:33,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:27<11:19,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:33<10:18,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:37<08:55,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:41<08:09,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:47<08:32,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:52<07:55,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:57<07:39,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [01:01<07:30,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [01:07<07:39,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [01:12<07:23,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [01:17<07:11,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [01:22<07:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [01:27<07:09,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:32<06:58,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:36<06:31,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [01:43<07:08,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [01:48<06:57,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [01:51<06:19,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [01:55<05:57,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [02:00<05:56,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [02:06<06:20,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [02:11<06:15,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [02:16<05:58,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [02:21<06:02,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [02:25<05:39,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [02:29<05:26,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [02:35<05:39,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [02:40<05:37,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [02:44<05:12,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [02:48<04:57,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [02:52<04:44,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [02:55<04:29,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [03:00<04:41,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [03:11<06:41,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [03:19<06:59,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [03:23<06:07,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [03:29<05:50,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [03:35<05:54,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [03:40<05:21,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [03:46<05:22,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [03:51<05:04,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [03:55<04:38,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [04:00<04:29,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [04:03<04:06,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [04:10<04:27,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [04:14<04:11,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [04:19<04:06,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [04:28<05:03,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [04:34<04:48,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [04:40<04:49,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [04:45<04:20,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [04:49<03:54,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [04:54<03:50,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [04:59<03:32,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [05:04<03:32,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [05:11<03:53,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [05:15<03:30,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [05:19<03:10,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [05:23<02:57,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [05:28<02:51,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [05:32<02:42,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [05:37<02:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [05:43<02:49,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [05:50<03:04,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [05:56<03:06,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [06:02<02:57,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [06:07<02:50,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [06:13<02:49,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [06:18<02:32,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [06:24<02:29,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [06:29<02:18,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [06:35<02:18,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [06:39<02:07,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [06:44<01:59,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [06:49<01:52,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [06:55<01:49,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [07:00<01:44,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [07:06<01:41,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [07:11<01:36,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [07:18<01:39,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [07:25<01:38,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [07:31<01:33,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [07:37<01:25,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [07:42<01:15,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [07:47<01:06,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [07:53<01:02,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [08:01<01:04,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [08:07<00:56,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [08:15<00:53,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [08:22<00:48,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [08:29<00:40,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [08:37<00:35,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [08:43<00:27,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [08:49<00:19,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [08:54<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [09:00<00:06,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:06<00:00,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.899741</td>\n",
       "      <td>0.907330</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.948913</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>0.806389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.037724</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>0.070740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.783810</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.498554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.932429</td>\n",
       "      <td>0.069631</td>\n",
       "      <td>0.754021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.951677</td>\n",
       "      <td>0.087016</td>\n",
       "      <td>0.813397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.846336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184404</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy     precision        recall            f1           auc  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.904255      0.899741      0.907330      0.902092      0.948913   \n",
       "std        0.035172      0.054143      0.048802      0.037724      0.026454   \n",
       "min        0.753846      0.657143      0.666667      0.745098      0.783810   \n",
       "25%        0.876923      0.864865      0.875000      0.877193      0.932429   \n",
       "50%        0.907692      0.904762      0.909091      0.904110      0.951677   \n",
       "75%        0.923077      0.939394      0.939394      0.928571      0.968391   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              brier         kappa  \n",
       "count  10000.000000  10000.000000  \n",
       "mean       0.087696      0.806389  \n",
       "std        0.025602      0.070740  \n",
       "min        0.010530      0.498554  \n",
       "25%        0.069631      0.754021  \n",
       "50%        0.087016      0.813397  \n",
       "75%        0.105634      0.846336  \n",
       "max        0.184404      1.000000  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "\n",
    "df_score_all = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "df_score_block = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "\n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "T6 = 0\n",
    "T7 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "brier_score = 0\n",
    "kappa_score = 0\n",
    "\n",
    "accuracy_all=[]\n",
    "precision_all=[]\n",
    "recall_all=[]\n",
    "f1score_all=[]\n",
    "auc_all=[]\n",
    "kappa_all=[]\n",
    "brier_all=[]\n",
    "\n",
    "accuracy_block=[]\n",
    "precision_block=[]\n",
    "recall_block=[]\n",
    "f1score_block=[]\n",
    "auc_block=[]\n",
    "kappa_block=[]\n",
    "brier_block=[]\n",
    "\n",
    "\n",
    "hist_Ep = []\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "    BOX = c92_copy2[c92_copy2.Species_18 != 'species name'].reset_index(drop = True)\n",
    "    sample = BOX[quiz:].sample(n=quiz, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:quiz], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    # MCz = c92_copy22[PTYPE]\n",
    "    MCz = c92_copy22[DJ]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "        \n",
    "        f = brier_score_loss(y_test, ws100_pred_proba)\n",
    "        g = cohen_kappa_score(ws100_preds, y_test)\n",
    "        brier_score = brier_score + f\n",
    "        kappa_score = kappa_score + g\n",
    "        \n",
    "        accuracy_all.append(a)\n",
    "        precision_all.append(b)\n",
    "        recall_all.append(c)\n",
    "        f1score_all.append(d)\n",
    "        auc_all.append(e)\n",
    "        brier_all.append(f)\n",
    "        kappa_all.append(g)\n",
    "        \n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        hist_Ep.append(a)\n",
    "\n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "#        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "        potcast.extend(mask.index.tolist())\n",
    "#         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "#         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "#    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "    brier_score/len(pot)\n",
    "    kappa_score/len(pot)\n",
    "    \n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    T6 = T6 + (brier_score/len(pot))\n",
    "    T7 = T7 + (kappa_score/len(pot))\n",
    "    \n",
    "    accuracy_block.append(accuracys/len(pot))\n",
    "    precision_block.append(precisions/len(pot))\n",
    "    recall_block.append(recalls/len(pot))\n",
    "    f1score_block.append(f1s/len(pot))\n",
    "    auc_block.append(roc_aucs/len(pot))\n",
    "    kappa_block.append(kappa_score/len(pot))\n",
    "    brier_block.append(brier_score/len(pot))\n",
    "        \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "    brier_score = 0\n",
    "    kappa_score = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n",
    "T6/len(hot)\n",
    "T7/len(hot)\n",
    "\n",
    "\n",
    "num_bins = 20 # <- number of bins for the histogram\n",
    "plt.hist(hist_Ep, num_bins)\n",
    "plt.show()\n",
    "\n",
    "sum(hist_Ep)/len(hist_Ep)\n",
    "\n",
    "df_score_all['accuracy']=accuracy_all\n",
    "df_score_all['precision']=precision_all\n",
    "df_score_all['recall']=recall_all\n",
    "df_score_all['f1']=f1score_all\n",
    "df_score_all['auc']=auc_all\n",
    "df_score_all['brier']=brier_all\n",
    "df_score_all['kappa']=kappa_all\n",
    "\n",
    "df_score_block['accuracy']=accuracy_block\n",
    "df_score_block['precision']=precision_block\n",
    "df_score_block['recall']=recall_block\n",
    "df_score_block['f1']=f1score_block\n",
    "df_score_block['auc']=auc_block\n",
    "df_score_block['brier']=brier_block\n",
    "df_score_block['kappa']=kappa_block\n",
    "\n",
    "\n",
    "df_score_all.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'DJ'+\"_scores_all.csv\")\n",
    "df_score_block.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'DJ'+\"_scores_block.csv\")\n",
    "\n",
    "df_score_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "006b79db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<<<<주요종만sopr>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-7ba94c5d80c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mxgb_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary:logistic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n\u001b[0m\u001b[1;32m     71\u001b[0m                             eval_metric=\"error\", eval_set=evals, verbose=0)\n\u001b[1;32m     72\u001b[0m         \u001b[0mws100_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    907\u001b[0m             eval_group=None, label_transform=label_transform)\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[1;32m    910\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "\n",
    "df_score_all = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "df_score_block = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "\n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "T6 = 0\n",
    "T7 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "brier_score = 0\n",
    "kappa_score = 0\n",
    "\n",
    "accuracy_all=[]\n",
    "precision_all=[]\n",
    "recall_all=[]\n",
    "f1score_all=[]\n",
    "auc_all=[]\n",
    "kappa_all=[]\n",
    "brier_all=[]\n",
    "\n",
    "accuracy_block=[]\n",
    "precision_block=[]\n",
    "recall_block=[]\n",
    "f1score_block=[]\n",
    "auc_block=[]\n",
    "kappa_block=[]\n",
    "brier_block=[]\n",
    "\n",
    "\n",
    "hist_Ep = []\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "    BOX = c92_copy2[c92_copy2.Species_18 != 'species name'].reset_index(drop = True)\n",
    "    sample = BOX[quiz:].sample(n=quiz, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:quiz], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    # MCz = c92_copy22[PTYPE]\n",
    "    MCz = c92_copy22[MC]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "        \n",
    "        f = brier_score_loss(y_test, ws100_pred_proba)\n",
    "        g = cohen_kappa_score(ws100_preds, y_test)\n",
    "        brier_score = brier_score + f\n",
    "        kappa_score = kappa_score + g\n",
    "        \n",
    "        accuracy_all.append(a)\n",
    "        precision_all.append(b)\n",
    "        recall_all.append(c)\n",
    "        f1score_all.append(d)\n",
    "        auc_all.append(e)\n",
    "        brier_all.append(f)\n",
    "        kappa_all.append(g)\n",
    "        \n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        hist_Ep.append(a)\n",
    "\n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "#        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "        potcast.extend(mask.index.tolist())\n",
    "#         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "#         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "#    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "    brier_score/len(pot)\n",
    "    kappa_score/len(pot)\n",
    "    \n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    T6 = T6 + (brier_score/len(pot))\n",
    "    T7 = T7 + (kappa_score/len(pot))\n",
    "    \n",
    "    accuracy_block.append(accuracys/len(pot))\n",
    "    precision_block.append(precisions/len(pot))\n",
    "    recall_block.append(recalls/len(pot))\n",
    "    f1score_block.append(f1s/len(pot))\n",
    "    auc_block.append(roc_aucs/len(pot))\n",
    "    kappa_block.append(kappa_score/len(pot))\n",
    "    brier_block.append(brier_score/len(pot))\n",
    "        \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "    brier_score = 0\n",
    "    kappa_score = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n",
    "T6/len(hot)\n",
    "T7/len(hot)\n",
    "\n",
    "\n",
    "num_bins = 20 # <- number of bins for the histogram\n",
    "plt.hist(hist_Ep, num_bins)\n",
    "plt.show()\n",
    "\n",
    "sum(hist_Ep)/len(hist_Ep)\n",
    "\n",
    "df_score_all['accuracy']=accuracy_all\n",
    "df_score_all['precision']=precision_all\n",
    "df_score_all['recall']=recall_all\n",
    "df_score_all['f1']=f1score_all\n",
    "df_score_all['auc']=auc_all\n",
    "df_score_all['brier']=brier_all\n",
    "df_score_all['kappa']=kappa_all\n",
    "\n",
    "df_score_block['accuracy']=accuracy_block\n",
    "df_score_block['precision']=precision_block\n",
    "df_score_block['recall']=recall_block\n",
    "df_score_block['f1']=f1score_block\n",
    "df_score_block['auc']=auc_block\n",
    "df_score_block['brier']=brier_block\n",
    "df_score_block['kappa']=kappa_block\n",
    "\n",
    "\n",
    "df_score_all.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'DJ'+\"_scores_all.csv\")\n",
    "df_score_block.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'DJ'+\"_scores_block.csv\")\n",
    "\n",
    "df_score_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c97eafdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<<<<주요종만sopr>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:13<22:05, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:24<19:41, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:35<18:29, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:46<17:54, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:56<17:20, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [01:06<16:28, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [01:16<15:59, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [01:28<16:38, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [01:48<15:45, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [01:58<15:05, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [02:09<15:17, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [02:22<16:19, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [02:33<16:14, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [02:45<16:18, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [02:57<16:09, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [03:07<15:28, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [03:22<16:39, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [03:32<15:51, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [03:44<15:31, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [04:01<17:24, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [04:16<18:02, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [04:52<26:06, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [05:39<36:13, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [05:57<31:36, 25.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [06:10<26:32, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [06:23<23:15, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [06:39<21:45, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [06:53<20:03, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [07:04<17:45, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [07:16<16:12, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [07:28<15:25, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [07:42<15:19, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [07:56<15:07, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [08:09<14:39, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [08:26<15:28, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [08:48<17:39, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [09:06<17:43, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [09:22<16:54, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [09:39<16:47, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [10:02<18:24, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [10:19<17:38, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [10:36<16:55, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [10:49<15:25, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [11:08<15:50, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [11:20<14:00, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [11:33<13:09, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [11:48<12:54, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [12:01<12:10, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [12:14<11:38, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [12:25<10:36, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [12:40<10:52, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [12:56<11:14, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [13:08<10:24, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [13:22<10:15, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [13:41<11:11, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [13:55<10:39, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [14:22<12:59, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [14:40<12:32, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [15:18<16:07, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [15:34<14:11, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [15:57<14:06, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [16:13<12:27, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [16:31<11:50, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [16:52<11:40, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [17:09<10:51, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [17:22<09:26, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [17:32<08:06, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [17:46<07:35, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [18:07<08:17, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [18:22<07:51, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [18:49<09:05, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [19:16<09:42, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [19:40<09:39, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [19:56<08:34, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [20:12<07:41, 19.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [20:26<06:41, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [20:43<06:24, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [21:00<05:59, 17.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [21:17<05:42, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [21:37<05:42, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [21:53<05:15, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [22:12<05:04, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [22:28<04:37, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [22:43<04:11, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [22:59<03:49, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [23:16<03:37, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [23:31<03:14, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [23:47<02:55, 15.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [24:01<02:32, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [24:13<02:11, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [24:26<01:51, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [24:38<01:33, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [24:52<01:20, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [25:14<01:21, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [25:38<01:13, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [25:51<00:50, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [26:06<00:32, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [26:25<00:17, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [26:44<00:00, 16.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.908809</td>\n",
       "      <td>0.902007</td>\n",
       "      <td>0.914815</td>\n",
       "      <td>0.907020</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.084447</td>\n",
       "      <td>0.815609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.053118</td>\n",
       "      <td>0.047020</td>\n",
       "      <td>0.036717</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>0.069215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.830492</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.537696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.066415</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.955408</td>\n",
       "      <td>0.083559</td>\n",
       "      <td>0.814991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.970952</td>\n",
       "      <td>0.102087</td>\n",
       "      <td>0.873418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180880</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy     precision        recall            f1           auc  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.908809      0.902007      0.914815      0.907020      0.951814   \n",
       "std        0.034387      0.053118      0.047020      0.036717      0.025950   \n",
       "min        0.769231      0.647059      0.733333      0.740741      0.830492   \n",
       "25%        0.892308      0.866667      0.884615      0.883117      0.935484   \n",
       "50%        0.907692      0.906250      0.916667      0.909091      0.955408   \n",
       "75%        0.938462      0.939394      0.945946      0.933333      0.970952   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              brier         kappa  \n",
       "count  10000.000000  10000.000000  \n",
       "mean       0.084447      0.815609  \n",
       "std        0.025358      0.069215  \n",
       "min        0.009048      0.537696  \n",
       "25%        0.066415      0.777070  \n",
       "50%        0.083559      0.814991  \n",
       "75%        0.102087      0.873418  \n",
       "max        0.180880      1.000000  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "\n",
    "df_score_all = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "df_score_block = pd.DataFrame({\"accuracy\":[],\"precision\":[], \"recall\":[], \"f1\":[], \"auc\":[], \"brier\":[], \"kappa\":[]})\n",
    "\n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "T6 = 0\n",
    "T7 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "brier_score = 0\n",
    "kappa_score = 0\n",
    "\n",
    "accuracy_all=[]\n",
    "precision_all=[]\n",
    "recall_all=[]\n",
    "f1score_all=[]\n",
    "auc_all=[]\n",
    "kappa_all=[]\n",
    "brier_all=[]\n",
    "\n",
    "accuracy_block=[]\n",
    "precision_block=[]\n",
    "recall_block=[]\n",
    "f1score_block=[]\n",
    "auc_block=[]\n",
    "kappa_block=[]\n",
    "brier_block=[]\n",
    "\n",
    "\n",
    "hist_Ep = []\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "    BOX = c92_copy2[c92_copy2.Species_18 != 'species name'].reset_index(drop = True)\n",
    "    sample = BOX[quiz:].sample(n=quiz, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:quiz], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    # MCz = c92_copy22[PTYPE]\n",
    "    MCz = c92_copy22[BEATMKR]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "        \n",
    "        f = brier_score_loss(y_test, ws100_pred_proba)\n",
    "        g = cohen_kappa_score(ws100_preds, y_test)\n",
    "        brier_score = brier_score + f\n",
    "        kappa_score = kappa_score + g\n",
    "        \n",
    "        accuracy_all.append(a)\n",
    "        precision_all.append(b)\n",
    "        recall_all.append(c)\n",
    "        f1score_all.append(d)\n",
    "        auc_all.append(e)\n",
    "        brier_all.append(f)\n",
    "        kappa_all.append(g)\n",
    "        \n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        hist_Ep.append(a)\n",
    "\n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "#        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "        potcast.extend(mask.index.tolist())\n",
    "#         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "#         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "#    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "    brier_score/len(pot)\n",
    "    kappa_score/len(pot)\n",
    "    \n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    T6 = T6 + (brier_score/len(pot))\n",
    "    T7 = T7 + (kappa_score/len(pot))\n",
    "    \n",
    "    accuracy_block.append(accuracys/len(pot))\n",
    "    precision_block.append(precisions/len(pot))\n",
    "    recall_block.append(recalls/len(pot))\n",
    "    f1score_block.append(f1s/len(pot))\n",
    "    auc_block.append(roc_aucs/len(pot))\n",
    "    kappa_block.append(kappa_score/len(pot))\n",
    "    brier_block.append(brier_score/len(pot))\n",
    "        \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "    brier_score = 0\n",
    "    kappa_score = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n",
    "T6/len(hot)\n",
    "T7/len(hot)\n",
    "\n",
    "\n",
    "num_bins = 20 # <- number of bins for the histogram\n",
    "plt.hist(hist_Ep, num_bins)\n",
    "plt.show()\n",
    "\n",
    "sum(hist_Ep)/len(hist_Ep)\n",
    "\n",
    "df_score_all['accuracy']=accuracy_all\n",
    "df_score_all['precision']=precision_all\n",
    "df_score_all['recall']=recall_all\n",
    "df_score_all['f1']=f1score_all\n",
    "df_score_all['auc']=auc_all\n",
    "df_score_all['brier']=brier_all\n",
    "df_score_all['kappa']=kappa_all\n",
    "\n",
    "df_score_block['accuracy']=accuracy_block\n",
    "df_score_block['precision']=precision_block\n",
    "df_score_block['recall']=recall_block\n",
    "df_score_block['f1']=f1score_block\n",
    "df_score_block['auc']=auc_block\n",
    "df_score_block['brier']=brier_block\n",
    "df_score_block['kappa']=kappa_block\n",
    "\n",
    "\n",
    "df_score_all.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'BTMKR'+\"_scores_all.csv\")\n",
    "df_score_block.to_csv(\"./score_bag(output)/\"+str(target_species)+'_'+'BTMKR'+\"_scores_block.csv\")\n",
    "\n",
    "df_score_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850692ed",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d55a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 50))\n",
    "pot = list(range(0, 10)) ###############################원래 100인데 5로 바꿈!!!!####################################\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "\n",
    "potcast = [] ####@@@@@@@###\n",
    "\n",
    "captain_Q_all = pd.DataFrame(columns=['name','shap_index'])\n",
    "captain_Q_75 = pd.DataFrame(columns=['name','shap_index'])\n",
    "captain_Q_95 = pd.DataFrame(columns=['name','shap_index'])\n",
    "\n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "#     sample = c92_copy2[294:].sample(n=294, random_state = k)\n",
    "#     c92_copy22 = pd.concat([c92_copy2[:294], sample])\n",
    "\n",
    "    BOX = c92_copy2.reset_index(drop = True)\n",
    "    sample = BOX[1439:].sample(n=1439, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:1439], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "\n",
    "   #################\n",
    "    LABEL = DJ ##### 여기에 변수이름 입력하기!!!\n",
    "   #################\n",
    "    MCz = c92_copy22[LABEL]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        \n",
    "        shap.initjs()\n",
    "        explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "        shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "        vals= np.abs(shap_values).mean(0)\n",
    "        feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "        feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "        \n",
    "        captain_Q_all = pd.concat([captain_Q_all, feature_importance])\n",
    "        \n",
    "        if accuracys > 0.999:\n",
    "            print('accuracys > 0.999')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "        \n",
    "            vals= np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "            feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "            \n",
    "            captain_Q_95 = pd.concat([captain_Q_95, feature_importance])\n",
    "            \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "#             taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "#             taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "#             traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "#             traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "# #            traffic_jam['error_frequency']\n",
    "\n",
    "#             traffic_jam['error_chance'] = 0\n",
    "#             traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "#             traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "# #            traffic_jam['error_chance']\n",
    "\n",
    "# #            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "#             traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "#             traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "#             traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "# #             plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "# #             plt.title('Presence', fontsize=20)\n",
    "\n",
    "# #             plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "# #             plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "# #             plt.show()\n",
    "\n",
    "\n",
    "# #             traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "# #             plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "# #             plt.title('Absence', fontsize=20)\n",
    "\n",
    "# #             plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "# #             plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "# #             plt.show()\n",
    "            \n",
    "            \n",
    "#             dice = X_train.index.tolist()\n",
    "#             NAMS = traffic_jam.iloc[dice]\n",
    "# #             NAMS['Species_18'].value_counts(normalize=True)\n",
    "# #             NAMS['Year'].value_counts()\n",
    "\n",
    "            \n",
    "            \n",
    "        elif accuracys < 0.75:\n",
    "            print('accuracys < 0.75')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "            \n",
    "            vals= np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "            feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "            captain_Q_75 = pd.concat([captain_Q_75, feature_importance])\n",
    "  \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "#             taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "#             taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "#             traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "#             traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "# #            traffic_jam['error_frequency']\n",
    "\n",
    "#             traffic_jam['error_chance'] = 0\n",
    "#             traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "#             traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "# #            traffic_jam['error_chance']\n",
    "\n",
    "# #            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "#             traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "#             traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "#             traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "# #             plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "# #             plt.title('Presence', fontsize=20)\n",
    "\n",
    "# #             plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "# #             plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "# #             plt.show()\n",
    "\n",
    "\n",
    "# #             traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "# #             plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "# #             plt.title('Absence', fontsize=20)\n",
    "\n",
    "# #             plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "# #             plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "# #             plt.show()\n",
    "            \n",
    "            \n",
    "#             dice = X_train.index.tolist()\n",
    "#             NAMS = traffic_jam.iloc[dice]\n",
    "# #             NAMS['Species_18'].value_counts(normalize=True)\n",
    "# #             NAMS['Year'].value_counts()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#         mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "# #        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "#         potcast.extend(mask.index.tolist())\n",
    "# #         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "# #         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "#         allpot.extend(potcast)\n",
    "\n",
    "        \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n",
    "\n",
    "captain_Q_all = captain_Q_all.reset_index(drop=True)\n",
    "captain_jam_all = captain_Q_all[['name', 'shap_index']][0:len(LABEL)].copy()\n",
    "captain_Q_75 = captain_Q_75.reset_index(drop=True)\n",
    "captain_jam_75 = captain_Q_75[['name', 'shap_index']][0:len(LABEL)].copy()\n",
    "captain_Q_95 = captain_Q_95.reset_index(drop=True)\n",
    "captain_jam_95 = captain_Q_95[['name', 'shap_index']][0:len(LABEL)].copy()\n",
    "\n",
    "\n",
    "a=0\n",
    "for i in LABEL:\n",
    "    try:\n",
    "        captain_jam_all['name'][a] = i\n",
    "        knife = captain_Q_all[captain_Q_all['col_name'] == i]['feature_importance_vals'].mean()\n",
    "        captain_jam_all['shap_index'][a] = knife\n",
    "        a=a+1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "a=0\n",
    "for i in LABEL:\n",
    "    try:\n",
    "        captain_jam_75['name'][a] = i\n",
    "        knife = captain_Q_75[captain_Q_75['col_name'] == i]['feature_importance_vals'].mean()\n",
    "        captain_jam_75['shap_index'][a] = knife\n",
    "        a=a+1\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "a=0\n",
    "for i in LABEL:\n",
    "    try:\n",
    "        captain_jam_95['name'][a] = i\n",
    "        knife = captain_Q_95[captain_Q_95['col_name'] == i]['feature_importance_vals'].mean()\n",
    "        captain_jam_95['shap_index'][a] = knife\n",
    "        a=a+1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "captain_jam_all = captain_jam_all.sort_values(by='shap_index', ascending=False)\n",
    "captain_jam_all\n",
    "captain_jam_75 = captain_jam_75.sort_values(by='shap_index', ascending=False)\n",
    "captain_jam_75\n",
    "captain_jam_95 = captain_jam_95.sort_values(by='shap_index', ascending=False)\n",
    "captain_jam_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captain_jam_all.to_csv('./bipunc_3MCs_DJ_jam_all.csv')\n",
    "captain_jam_75.to_csv('./bipunc_3MCs_DJ_jam_75.csv')\n",
    "captain_jam_95.to_csv('./bipunc_3MCs_DJ_jam_95.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08214630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894e312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c83c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00003d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 1)) ###############################원래 100인데 5로 바꿈!!!!####################################\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "#     sample = c92_copy2[294:].sample(n=294, random_state = k)\n",
    "#     c92_copy22 = pd.concat([c92_copy2[:294], sample])\n",
    "\n",
    "    BOX = c92_copy2[(c92_copy2.Species_18 == 'Coccinella novemnotata')|(c92_copy2.Species_18 == 'Coccinella septempunctata')].reset_index(drop = True)\n",
    "    sample = BOX[294:].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:294], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    MCz = c92_copy22[BEATMKR]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        \n",
    "        if accuracys < 0.85:\n",
    "            print('accuracys < 0.85')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            \n",
    "            shap.summary_plot(shap_values, X_train)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             feature_names = shap_values.feature_names\n",
    "#             shap_df = pd.DataFrame(shap_values.values, columns=feature_names)\n",
    "#             vals = np.abs(shap_df.values).mean(0)\n",
    "#             shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name', 'feature_importance_vals'])\n",
    "#             shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "            vals= np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "            feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "            feature_importance.head()\n",
    "\n",
    "            \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "            taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "            taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "            traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "            traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "#            traffic_jam['error_frequency']\n",
    "\n",
    "            traffic_jam['error_chance'] = 0\n",
    "            traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "            traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "#            traffic_jam['error_chance']\n",
    "\n",
    "#            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "            traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "            plt.title('Presence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "            plt.title('Absence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            dice = X_train.index.tolist()\n",
    "            NAMS = traffic_jam.iloc[dice]\n",
    "            NAMS['Species_18'].value_counts(normalize=True)\n",
    "            NAMS['Year'].value_counts()\n",
    "\n",
    "            \n",
    "            \n",
    "        elif accuracys > 0.95:\n",
    "            print('accuracys > 0.97')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            \n",
    "            shap.summary_plot(shap_values, X_train)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             feature_names = shap_values.feature_names\n",
    "#             shap_df = pd.DataFrame(shap_values.values, columns=feature_names)\n",
    "#             vals = np.abs(shap_df.values).mean(0)\n",
    "#             shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name', 'feature_importance_vals'])\n",
    "#             shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "            \n",
    "            vals= np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "            feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "            feature_importance.head()\n",
    "  \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "            taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "            taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "            traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "            traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "#            traffic_jam['error_frequency']\n",
    "\n",
    "            traffic_jam['error_chance'] = 0\n",
    "            traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "            traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "#            traffic_jam['error_chance']\n",
    "\n",
    "#            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "            traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "            plt.title('Presence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "            plt.title('Absence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            dice = X_train.index.tolist()\n",
    "            NAMS = traffic_jam.iloc[dice]\n",
    "            NAMS['Species_18'].value_counts(normalize=True)\n",
    "            NAMS['Year'].value_counts()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "        potcast.extend(mask.index.tolist())\n",
    "        allpot.extend(potcast)\n",
    "\n",
    "        \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 5)) ###############################원래 100인데 5로 바꿈!!!!####################################\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "    sample = c92_copy2[294:].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([c92_copy2[:294], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    MCz = c92_copy22[DJ]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        \n",
    "        if accuracys < 0.7:\n",
    "            print('accuracys < 0.7')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            \n",
    "            shap.summary_plot(shap_values, X_train)\n",
    "            \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "            taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "            taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "            traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "            traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "#            traffic_jam['error_frequency']\n",
    "\n",
    "            traffic_jam['error_chance'] = 0\n",
    "            traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "            traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "#            traffic_jam['error_chance']\n",
    "\n",
    "#            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "            traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "            plt.title('Presence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "            plt.title('Absence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            dice = X_train.index.tolist()\n",
    "            NAMS = traffic_jam.iloc[dice]\n",
    "            NAMS['Species_18'].value_counts(normalize=True)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif accuracys > 0.95:\n",
    "            print('accuracys > 0.97')\n",
    "            \n",
    "            shap.initjs()\n",
    "            explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            \n",
    "            shap.summary_plot(shap_values, X_train)\n",
    "            \n",
    "            \n",
    "            b = Counter(potcast)\n",
    "\n",
    "            taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "            taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "            traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "            traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "#            traffic_jam['error_frequency']\n",
    "\n",
    "            traffic_jam['error_chance'] = 0\n",
    "            traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "            traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "#            traffic_jam['error_chance']\n",
    "\n",
    "#            traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "            traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "            traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "            plt.title('Presence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "            plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "            plt.title('Absence', fontsize=20)\n",
    "\n",
    "            plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "            plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            dice = X_train.index.tolist()\n",
    "            NAMS = traffic_jam.iloc[dice]\n",
    "            NAMS['Species_18'].value_counts(normalize=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "#        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "        potcast.extend(mask.index.tolist())\n",
    "#         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "#         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "        allpot.extend(potcast)\n",
    "\n",
    "        \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non SMOTE 버전\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "\n",
    "potcast = [] ####@@@@@@@###\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "#     sample = c92_copy2[:1915].sample(n=288, random_state = k) # 07,08 제외시\n",
    "#     c92_copy22 = pd.concat([c92_copy2[1915:], sample])\n",
    "    sample = c92_copy2[294:].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([c92_copy2[:294], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    \n",
    "    MCz = c92_copy22[BEATMKR]\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "        get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        \n",
    "        mask = np.logical_not(np.equal(y_test, ws100_preds))\n",
    "#        print(f\"Elements wrong classified: {X_test[mask].index}\")\n",
    "        potcast.extend(mask.index.tolist())\n",
    "#         print(f\"Prediction by the model for each of those elements: {predictions[mask]}\")\n",
    "#         print(f\"Actual value for each of those elements: {np.asarray(y_test)[mask]}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6)) # 축b 반환\n",
    "plot_importance(xgb_wrapper, ax=ax) # 학습이 된 xgb_model과 축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpot.extend(potcast)\n",
    "\n",
    "b = Counter(potcast)\n",
    "\n",
    "taggerz = pd.DataFrame.from_dict(b, orient ='index')\n",
    "taggerz.rename(columns={0:'error_frequency'}, inplace=True)\n",
    "\n",
    "traffic_jam = pd.merge(c92zet, taggerz, left_index=True, right_index=True, how='left')\n",
    "traffic_jam = traffic_jam.fillna(0)\n",
    "\n",
    "traffic_jam['error_frequency']\n",
    "\n",
    "traffic_jam['error_chance'] = 0\n",
    "traffic_jam['error_chance'][:294] = traffic_jam['error_frequency'][:294]/(len(hot)*len(pot))\n",
    "traffic_jam['error_chance'][294:] = traffic_jam['error_frequency'][294:]/((len(c92_copy2[:294].index)*(len(hot)*len(pot)))/len(c92_copy2[294:].index))\n",
    "traffic_jam['error_chance']\n",
    "\n",
    "traffic_jam.sort_values(by='error_chance', axis=0, ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_jam2 = traffic_jam[traffic_jam.target==1].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "traffic_jam3 = traffic_jam[traffic_jam.target==0].sort_values(by='Year', axis=0, ascending=False, inplace=False)\n",
    "\n",
    "\n",
    "traffic_jam2_5 = traffic_jam2.groupby('Year').error_frequency.mean()\n",
    "\n",
    "plt.bar(traffic_jam2_5.index, traffic_jam2_5)\n",
    "\n",
    "plt.title('Presence', fontsize=20)\n",
    "\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "traffic_jam3_5 = traffic_jam3.groupby('Year').error_frequency.mean()\n",
    "\n",
    "plt.bar(traffic_jam3_5.index, traffic_jam3_5)\n",
    "\n",
    "plt.title('Absence', fontsize=20)\n",
    "\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "\n",
    "plt.ylabel('error_chance', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(xgb_wrapper)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[4, :], X_train.iloc[4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "# 총 13개 특성의 Shapley value를 절댓값 변환 후 각 특성마다 더함 -> np.argsort()는 작은 순서대로 정렬, 큰 순서대로 정렬하려면\n",
    "# 앞에 마이너스(-) 기호를 붙임\n",
    "top_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n",
    "\n",
    "# 영향력 top 2 컬럼\n",
    "for i in range(2):\n",
    "    shap.dependence_plot(top_inds[i], shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "\n",
    "# 진단1 : convergens와 septempunctata가 정확도를 낮추는 원인일 것(why? 크고 작고의 영향이 서로 구분되지 않음).\n",
    "# -> 이들의 영향을 구분하도록 데이터 프레임을 짜는 것이 관건\n",
    "## --> absence data 때문?\n",
    "## --> 다른 변수 추가로 해결 가능?\n",
    "\n",
    "\n",
    "# 진단2 : 잘 쓰이지 않는 변수\n",
    "# -> Subcoccinella_vigintiquatuorpunctata\n",
    "# -> Hippodamia_quinquesignata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "shap.summary_plot(shap_interaction_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805669b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    ('Hippodamia_convergens_18', 'Coccinella_septempunctata_18'),\n",
    "    shap_interaction_values, X_train,\n",
    "    display_features=X_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64004a",
   "metadata": {},
   "source": [
    "# 실전 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer 2년, gps 정확도 4.5 km, 관측신뢰도 전종 18km, 위협도 1km\n",
    "df = pd.read_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20211214_Newgeneration/실전테스트/20220201_실제 테스트 log화 완료.csv', index_col = 0)\n",
    "#c92 = pd.read_csv('/Users/hyun-yong/JPnotebook/LDYcol/10.csv for ML_new/20211214_Newgeneration/정규화/MINMAX스케일링/20220123_minmaxscaler.csv', index_col = 0)\n",
    "\n",
    "## C9 서식지만~!!!(실전에서 히포다미아는 제거)\n",
    "\n",
    "df= df[df['Species'] == 'Coccinella novemnotata']\n",
    "        \n",
    "\n",
    "### 나중에 이거를 500번 반복문에 넣기!!!!!!!!!1 저 최종 값도 500번의 평균으로 ㅇㅇㅇ\n",
    "###############\n",
    "###############\n",
    "###############\n",
    "###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aeff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68922ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "\n",
    "hist_Ep = []\n",
    "potcast = [] ####@@@@@@@###\n",
    "\n",
    "\n",
    "\n",
    "for i in range(2007,2022):\n",
    "        globals()['list_{}'.format(i)] = []\n",
    "        \n",
    "for k in tqdm(hot):\n",
    "    BOX = c92_copy2[c92_copy2.Species_18 != 'Hippodamia parenthesis'].reset_index(drop = True)\n",
    "    sample = BOX[294:].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([BOX[:294], sample])\n",
    "    c92sr2_y = c92_copy22.target\n",
    "    MCz = c92_copy22[DJ]\n",
    "\n",
    "    for i in pot:\n",
    "        ## stratify는 반복문으로 처리함 -- Original\n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음        \n",
    "        ## stratify 처리: 원래 이 기능은 원 데이터의 분류비를 유지한다는 개념인데, 여기서는 분류비를 50대50으로 맞춘 데이터 프레임을 사용하므로 테스트 세트를 50대50으로 구분하는 효과\n",
    "        ## 우리가 여기에만 stratify를 적용하는 이유: 우리가 맞추고 싶은 것은 기존 서식지에 계속 산다 살지 않는다이지, 서식지 추론 모델이 아님.\n",
    "        ## 따라서, absence 데이터의 양은 자연에서 발생한 '부재' 케이스에서 기인한 것이 아님. 그러므로 벨런스를 유지할 필요가 없음.\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i, stratify=c92sr2_y) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        xgb_wrapper = XGBClassifier(n_estimators=1000, learning_rate=0.7, max_depth=7, objective = \"binary:logistic\")\n",
    "        evals = [(X_test, y_test)]\n",
    "        xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                            eval_metric=\"error\", eval_set=evals, verbose=0)\n",
    "        ws100_preds = xgb_wrapper.predict(X_test)\n",
    "        ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         # 예측 성능 평가\n",
    "#         a, b, c, d, e = get_clf_eval_num(y_test, ws100_preds, ws100_pred_proba)\n",
    "#         accuracys = accuracys + a\n",
    "#         precisions = precisions + b\n",
    "#         recalls = recalls + c\n",
    "#         f1s = f1s + d\n",
    "#         roc_aucs = roc_aucs + e\n",
    "\n",
    "#         get_clf_eval(y_test, ws100_preds, ws100_pred_proba)\n",
    "        \n",
    "        \n",
    "\n",
    "#     print()\n",
    "#     print()\n",
    "#     print()\n",
    "#     print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "#     accuracys/len(pot)\n",
    "#     precisions/len(pot)\n",
    "#     recalls/len(pot)\n",
    "#     f1s/len(pot)\n",
    "#     roc_aucs/len(pot)\n",
    "               \n",
    "#     T1 = T1 + (accuracys/len(pot))\n",
    "#     T2 = T2 + (precisions/len(pot))\n",
    "#     T3 = T3 + (recalls/len(pot))\n",
    "#     T4 = T4 + (f1s/len(pot))\n",
    "#     T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "#     accuracys = 0\n",
    "#     precisions = 0\n",
    "#     recalls = 0\n",
    "#     f1s = 0\n",
    "#     roc_aucs = 0\n",
    "           \n",
    "# T1/len(hot)\n",
    "# T2/len(hot)\n",
    "# T3/len(hot)\n",
    "# T4/len(hot)\n",
    "# T5/len(hot)\n",
    "\n",
    "\n",
    "\n",
    "             # 고정 상수 제외\n",
    "        df09 = df[['quin_2007_18km',\n",
    "                       'trans_2007_18km',\n",
    "                       'chl_2007_18km',\n",
    "                       'cris_2007_18km',\n",
    "                       'axy_2007_18km',\n",
    "                       'quad_2007_18km',\n",
    "                       'exo_2007_18km',           \n",
    "                       'plec_2007_18km',\n",
    "                       'phaino_2007_18km',\n",
    "                       'aberti_2007_18km',\n",
    "                       'belli_2007_18km',\n",
    "                       'api_2007_18km',\n",
    "                       'gla_2007_18km',\n",
    "                       'case_2007_18km',\n",
    "                       'monti_2007_18km',\n",
    "                       'zono_2007_18km',\n",
    "                       'lonchura_2007_18km',\n",
    "                       'inter_2007_18km',\n",
    "                       'sub_2007_18km',\n",
    "                       'alpes_2007_18km', \n",
    "                       'hip_2007_18km', \n",
    "                       'c7_2007_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2007_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2007_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2007_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2007_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2007_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2007_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2007_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2007_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2007_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2007_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2007_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2007_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2007_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2007_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2007_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2007_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2007_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2007_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2007_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2007_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2007_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2007_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2007.append(results)\n",
    "\n",
    "        df09 = df[['quin_2008_18km',\n",
    "                       'trans_2008_18km',\n",
    "                       'chl_2008_18km',\n",
    "                       'cris_2008_18km',\n",
    "                       'axy_2008_18km',\n",
    "                       'quad_2008_18km',\n",
    "                       'exo_2008_18km',           \n",
    "                       'plec_2008_18km',\n",
    "                       'phaino_2008_18km',\n",
    "                       'aberti_2008_18km',\n",
    "                       'belli_2008_18km',\n",
    "                       'api_2008_18km',\n",
    "                       'gla_2008_18km',\n",
    "                       'case_2008_18km',\n",
    "                       'monti_2008_18km',\n",
    "                       'zono_2008_18km',\n",
    "                       'lonchura_2008_18km',\n",
    "                       'inter_2008_18km',\n",
    "                       'sub_2008_18km',\n",
    "                       'alpes_2008_18km', \n",
    "                       'hip_2008_18km', \n",
    "                       'c7_2008_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2008_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2008_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2008_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2008_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2008_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2008_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2008_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2008_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2008_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2008_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2008_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2008_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2008_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2008_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2008_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2008_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2008_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2008_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2008_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2008_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2008_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2008_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2008.append(results)\n",
    "        \n",
    "        \n",
    "        df09 = df[['quin_2009_18km',\n",
    "                       'trans_2009_18km',\n",
    "                       'chl_2009_18km',\n",
    "                       'cris_2009_18km',\n",
    "                       'axy_2009_18km',\n",
    "                       'quad_2009_18km',\n",
    "                       'exo_2009_18km',           \n",
    "                       'plec_2009_18km',\n",
    "                       'phaino_2009_18km',\n",
    "                       'aberti_2009_18km',\n",
    "                       'belli_2009_18km',\n",
    "                       'api_2009_18km',\n",
    "                       'gla_2009_18km',\n",
    "                       'case_2009_18km',\n",
    "                       'monti_2009_18km',\n",
    "                       'zono_2009_18km',\n",
    "                       'lonchura_2009_18km',\n",
    "                       'inter_2009_18km',\n",
    "                       'sub_2009_18km',\n",
    "                       'alpes_2009_18km', \n",
    "                       'hip_2009_18km', \n",
    "                       'c7_2009_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2009_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2009_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2009_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2009_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2009_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2009_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2009_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2009_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2009_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2009_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2009_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2009_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2009_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2009_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2009_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2009_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2009_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2009_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2009_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2009_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2009_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2009_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2009.append(results)\n",
    "\n",
    "        \n",
    "        df09 = df[['quin_2010_18km',\n",
    "                       'trans_2010_18km',\n",
    "                       'chl_2010_18km',\n",
    "                       'cris_2010_18km',\n",
    "                       'axy_2010_18km',\n",
    "                       'quad_2010_18km',\n",
    "                       'exo_2010_18km',           \n",
    "                       'plec_2010_18km',\n",
    "                       'phaino_2010_18km',\n",
    "                       'aberti_2010_18km',\n",
    "                       'belli_2010_18km',\n",
    "                       'api_2010_18km',\n",
    "                       'gla_2010_18km',\n",
    "                       'case_2010_18km',\n",
    "                       'monti_2010_18km',\n",
    "                       'zono_2010_18km',\n",
    "                       'lonchura_2010_18km',\n",
    "                       'inter_2010_18km',\n",
    "                       'sub_2010_18km',\n",
    "                       'alpes_2010_18km', \n",
    "                       'hip_2010_18km', \n",
    "                       'c7_2010_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2010_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2010_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2010_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2010_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2010_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2010_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2010_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2010_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2010_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2010_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2010_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2010_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2010_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2010_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2010_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2010_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2010_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2010_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2010_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2010_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2010_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2010_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2010.append(results)\n",
    "\n",
    "        df09 = df[['quin_2011_18km',\n",
    "                       'trans_2011_18km',\n",
    "                       'chl_2011_18km',\n",
    "                       'cris_2011_18km',\n",
    "                       'axy_2011_18km',\n",
    "                       'quad_2011_18km',\n",
    "                       'exo_2011_18km',           \n",
    "                       'plec_2011_18km',\n",
    "                       'phaino_2011_18km',\n",
    "                       'aberti_2011_18km',\n",
    "                       'belli_2011_18km',\n",
    "                       'api_2011_18km',\n",
    "                       'gla_2011_18km',\n",
    "                       'case_2011_18km',\n",
    "                       'monti_2011_18km',\n",
    "                       'zono_2011_18km',\n",
    "                       'lonchura_2011_18km',\n",
    "                       'inter_2011_18km',\n",
    "                       'sub_2011_18km',\n",
    "                       'alpes_2011_18km', \n",
    "                       'hip_2011_18km', \n",
    "                       'c7_2011_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2011_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2011_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2011_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2011_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2011_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2011_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2011_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2011_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2011_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2011_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2011_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2011_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2011_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2011_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2011_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2011_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2011_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2011_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2011_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2011_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2011_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2011_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2011.append(results)\n",
    "\n",
    "        df09 = df[['quin_2012_18km',\n",
    "                       'trans_2012_18km',\n",
    "                       'chl_2012_18km',\n",
    "                       'cris_2012_18km',\n",
    "                       'axy_2012_18km',\n",
    "                       'quad_2012_18km',\n",
    "                       'exo_2012_18km',           \n",
    "                       'plec_2012_18km',\n",
    "                       'phaino_2012_18km',\n",
    "                       'aberti_2012_18km',\n",
    "                       'belli_2012_18km',\n",
    "                       'api_2012_18km',\n",
    "                       'gla_2012_18km',\n",
    "                       'case_2012_18km',\n",
    "                       'monti_2012_18km',\n",
    "                       'zono_2012_18km',\n",
    "                       'lonchura_2012_18km',\n",
    "                       'inter_2012_18km',\n",
    "                       'sub_2012_18km',\n",
    "                       'alpes_2012_18km', \n",
    "                       'hip_2012_18km', \n",
    "                       'c7_2012_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2012_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2012_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2012_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2012_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2012_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2012_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2012_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2012_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2012_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2012_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2012_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2012_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2012_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2012_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2012_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2012_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2012_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2012_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2012_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2012_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2012_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2012_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2012.append(results)\n",
    "\n",
    "        df09 = df[['quin_2013_18km',\n",
    "                       'trans_2013_18km',\n",
    "                       'chl_2013_18km',\n",
    "                       'cris_2013_18km',\n",
    "                       'axy_2013_18km',\n",
    "                       'quad_2013_18km',\n",
    "                       'exo_2013_18km',           \n",
    "                       'plec_2013_18km',\n",
    "                       'phaino_2013_18km',\n",
    "                       'aberti_2013_18km',\n",
    "                       'belli_2013_18km',\n",
    "                       'api_2013_18km',\n",
    "                       'gla_2013_18km',\n",
    "                       'case_2013_18km',\n",
    "                       'monti_2013_18km',\n",
    "                       'zono_2013_18km',\n",
    "                       'lonchura_2013_18km',\n",
    "                       'inter_2013_18km',\n",
    "                       'sub_2013_18km',\n",
    "                       'alpes_2013_18km', \n",
    "                       'hip_2013_18km', \n",
    "                       'c7_2013_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2013_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2013_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2013_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2013_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2013_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2013_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2013_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2013_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2013_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2013_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2013_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2013_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2013_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2013_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2013_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2013_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2013_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2013_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2013_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2013_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2013_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2013_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2013.append(results)\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2014_18km',\n",
    "                       'trans_2014_18km',\n",
    "                       'chl_2014_18km',\n",
    "                       'cris_2014_18km',\n",
    "                       'axy_2014_18km',\n",
    "                       'quad_2014_18km',\n",
    "                       'exo_2014_18km',           \n",
    "                       'plec_2014_18km',\n",
    "                       'phaino_2014_18km',\n",
    "                       'aberti_2014_18km',\n",
    "                       'belli_2014_18km',\n",
    "                       'api_2014_18km',\n",
    "                       'gla_2014_18km',\n",
    "                       'case_2014_18km',\n",
    "                       'monti_2014_18km',\n",
    "                       'zono_2014_18km',\n",
    "                       'lonchura_2014_18km',\n",
    "                       'inter_2014_18km',\n",
    "                       'sub_2014_18km',\n",
    "                       'alpes_2014_18km', \n",
    "                       'hip_2014_18km', \n",
    "                       'c7_2014_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2014_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2014_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2014_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2014_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2014_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2014_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2014_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2014_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2014_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2014_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2014_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2014_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2014_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2014_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2014_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2014_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2014_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2014_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2014_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2014_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2014_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2014_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2014.append(results)\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2015_18km',\n",
    "                       'trans_2015_18km',\n",
    "                       'chl_2015_18km',\n",
    "                       'cris_2015_18km',\n",
    "                       'axy_2015_18km',\n",
    "                       'quad_2015_18km',\n",
    "                       'exo_2015_18km',           \n",
    "                       'plec_2015_18km',\n",
    "                       'phaino_2015_18km',\n",
    "                       'aberti_2015_18km',\n",
    "                       'belli_2015_18km',\n",
    "                       'api_2015_18km',\n",
    "                       'gla_2015_18km',\n",
    "                       'case_2015_18km',\n",
    "                       'monti_2015_18km',\n",
    "                       'zono_2015_18km',\n",
    "                       'lonchura_2015_18km',\n",
    "                       'inter_2015_18km',\n",
    "                       'sub_2015_18km',\n",
    "                       'alpes_2015_18km', \n",
    "                       'hip_2015_18km', \n",
    "                       'c7_2015_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2015_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2015_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2015_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2015_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2015_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2015_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2015_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2015_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2015_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2015_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2015_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2015_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2015_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2015_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2015_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2015_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2015_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2015_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2015_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2015_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2015_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2015_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2015.append(results)\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2016_18km',\n",
    "                       'trans_2016_18km',\n",
    "                       'chl_2016_18km',\n",
    "                       'cris_2016_18km',\n",
    "                       'axy_2016_18km',\n",
    "                       'quad_2016_18km',\n",
    "                       'exo_2016_18km',           \n",
    "                       'plec_2016_18km',\n",
    "                       'phaino_2016_18km',\n",
    "                       'aberti_2016_18km',\n",
    "                       'belli_2016_18km',\n",
    "                       'api_2016_18km',\n",
    "                       'gla_2016_18km',\n",
    "                       'case_2016_18km',\n",
    "                       'monti_2016_18km',\n",
    "                       'zono_2016_18km',\n",
    "                       'lonchura_2016_18km',\n",
    "                       'inter_2016_18km',\n",
    "                       'sub_2016_18km',\n",
    "                       'alpes_2016_18km', \n",
    "                       'hip_2016_18km', \n",
    "                       'c7_2016_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2016_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2016_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2016_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2016_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2016_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2016_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2016_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2016_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2016_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2016_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2016_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2016_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2016_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2016_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2016_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2016_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2016_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2016_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2016_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2016_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2016_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2016_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2016.append(results)\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2017_18km',\n",
    "                       'trans_2017_18km',\n",
    "                       'chl_2017_18km',\n",
    "                       'cris_2017_18km',\n",
    "                       'axy_2017_18km',\n",
    "                       'quad_2017_18km',\n",
    "                       'exo_2017_18km',           \n",
    "                       'plec_2017_18km',\n",
    "                       'phaino_2017_18km',\n",
    "                       'aberti_2017_18km',\n",
    "                       'belli_2017_18km',\n",
    "                       'api_2017_18km',\n",
    "                       'gla_2017_18km',\n",
    "                       'case_2017_18km',\n",
    "                       'monti_2017_18km',\n",
    "                       'zono_2017_18km',\n",
    "                       'lonchura_2017_18km',\n",
    "                       'inter_2017_18km',\n",
    "                       'sub_2017_18km',\n",
    "                       'alpes_2017_18km', \n",
    "                       'hip_2017_18km', \n",
    "                       'c7_2017_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2017_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2017_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2017_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2017_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2017_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2017_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2017_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2017_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2017_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2017_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2017_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2017_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2017_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2017_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2017_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2017_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2017_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2017_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2017_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2017_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2017_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2017_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2017.append(results)\n",
    "\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2018_18km',\n",
    "                       'trans_2018_18km',\n",
    "                       'chl_2018_18km',\n",
    "                       'cris_2018_18km',\n",
    "                       'axy_2018_18km',\n",
    "                       'quad_2018_18km',\n",
    "                       'exo_2018_18km',           \n",
    "                       'plec_2018_18km',\n",
    "                       'phaino_2018_18km',\n",
    "                       'aberti_2018_18km',\n",
    "                       'belli_2018_18km',\n",
    "                       'api_2018_18km',\n",
    "                       'gla_2018_18km',\n",
    "                       'case_2018_18km',\n",
    "                       'monti_2018_18km',\n",
    "                       'zono_2018_18km',\n",
    "                       'lonchura_2018_18km',\n",
    "                       'inter_2018_18km',\n",
    "                       'sub_2018_18km',\n",
    "                       'alpes_2018_18km', \n",
    "                       'hip_2018_18km', \n",
    "                       'c7_2018_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2018_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2018_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2018_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2018_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2018_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2018_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2018_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2018_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2018_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2018_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2018_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2018_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2018_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2018_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2018_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2018_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2018_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2018_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2018_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2018_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2018_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2018_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2018.append(results)\n",
    "\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2019_18km',\n",
    "                       'trans_2019_18km',\n",
    "                       'chl_2019_18km',\n",
    "                       'cris_2019_18km',\n",
    "                       'axy_2019_18km',\n",
    "                       'quad_2019_18km',\n",
    "                       'exo_2019_18km',           \n",
    "                       'plec_2019_18km',\n",
    "                       'phaino_2019_18km',\n",
    "                       'aberti_2019_18km',\n",
    "                       'belli_2019_18km',\n",
    "                       'api_2019_18km',\n",
    "                       'gla_2019_18km',\n",
    "                       'case_2019_18km',\n",
    "                       'monti_2019_18km',\n",
    "                       'zono_2019_18km',\n",
    "                       'lonchura_2019_18km',\n",
    "                       'inter_2019_18km',\n",
    "                       'sub_2019_18km',\n",
    "                       'alpes_2019_18km', \n",
    "                       'hip_2019_18km', \n",
    "                       'c7_2019_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2019_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2019_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2019_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2019_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2019_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2019_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2019_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2019_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2019_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2019_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2019_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2019_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2019_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2019_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2019_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2019_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2019_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2019_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2019_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2019_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2019_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2019_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2019.append(results)\n",
    "\n",
    "        df09 = df[['quin_2020_18km',\n",
    "                       'trans_2020_18km',\n",
    "                       'chl_2020_18km',\n",
    "                       'cris_2020_18km',\n",
    "                       'axy_2020_18km',\n",
    "                       'quad_2020_18km',\n",
    "                       'exo_2020_18km',           \n",
    "                       'plec_2020_18km',\n",
    "                       'phaino_2020_18km',\n",
    "                       'aberti_2020_18km',\n",
    "                       'belli_2020_18km',\n",
    "                       'api_2020_18km',\n",
    "                       'gla_2020_18km',\n",
    "                       'case_2020_18km',\n",
    "                       'monti_2020_18km',\n",
    "                       'zono_2020_18km',\n",
    "                       'lonchura_2020_18km',\n",
    "                       'inter_2020_18km',\n",
    "                       'sub_2020_18km',\n",
    "                       'alpes_2020_18km', \n",
    "                       'hip_2020_18km', \n",
    "                       'c7_2020_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2020_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2020_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2020_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2020_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2020_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2020_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2020_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2020_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2020_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2020_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2020_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2020_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2020_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2020_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2020_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2020_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2020_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2020_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2020_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2020_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2020_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2020_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2020.append(results)\n",
    "\n",
    "\n",
    "        df09 = df[['quin_2021_18km',\n",
    "                       'trans_2021_18km',\n",
    "                       'chl_2021_18km',\n",
    "                       'cris_2021_18km',\n",
    "                       'axy_2021_18km',\n",
    "                       'quad_2021_18km',\n",
    "                       'exo_2021_18km',           \n",
    "                       'plec_2021_18km',\n",
    "                       'phaino_2021_18km',\n",
    "                       'aberti_2021_18km',\n",
    "                       'belli_2021_18km',\n",
    "                       'api_2021_18km',\n",
    "                       'gla_2021_18km',\n",
    "                       'case_2021_18km',\n",
    "                       'monti_2021_18km',\n",
    "                       'zono_2021_18km',\n",
    "                       'lonchura_2021_18km',\n",
    "                       'inter_2021_18km',\n",
    "                       'sub_2021_18km',\n",
    "                       'alpes_2021_18km', \n",
    "                       'hip_2021_18km', \n",
    "                       'c7_2021_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2021_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2021_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2021_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2021_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2021_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2021_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2021_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2021_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2021_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2021_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2021_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2021_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2021_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2021_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2021_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2021_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2021_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2021_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2021_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2021_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2021_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2021_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2021.append(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('2007')\n",
    "sum(list_2007)/len(list_2007)\n",
    "print('2008')\n",
    "sum(list_2008)/len(list_2008)\n",
    "print('2009')\n",
    "sum(list_2009)/len(list_2009)\n",
    "print('2010')\n",
    "sum(list_2010)/len(list_2010)\n",
    "print('2011')\n",
    "sum(list_2011)/len(list_2011)\n",
    "print('2012')\n",
    "sum(list_2012)/len(list_2012)\n",
    "print('2013')\n",
    "sum(list_2013)/len(list_2013)\n",
    "print('2014')\n",
    "sum(list_2014)/len(list_2014)\n",
    "print('2015')\n",
    "sum(list_2015)/len(list_2015)\n",
    "print('2016')\n",
    "sum(list_2016)/len(list_2016)\n",
    "print('2017')\n",
    "sum(list_2017)/len(list_2017)\n",
    "print('2018')\n",
    "sum(list_2018)/len(list_2018)\n",
    "print('2019')\n",
    "sum(list_2019)/len(list_2019)\n",
    "print('2020')\n",
    "sum(list_2020)/len(list_2020)\n",
    "print('2021')\n",
    "sum(list_2021)/len(list_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        df09 = df[['quin_2021_18km',\n",
    "                       'trans_2021_18km',\n",
    "                       'chl_2021_18km',\n",
    "                       'cris_2021_18km',\n",
    "                       'axy_2021_18km',\n",
    "                       'quad_2021_18km',\n",
    "                       'exo_2021_18km',           \n",
    "                       'plec_2021_18km',\n",
    "                       'phaino_2021_18km',\n",
    "                       'aberti_2021_18km',\n",
    "                       'belli_2021_18km',\n",
    "                       'api_2021_18km',\n",
    "                       'gla_2021_18km',\n",
    "                       'case_2021_18km',\n",
    "                       'monti_2021_18km',\n",
    "                       'zono_2021_18km',\n",
    "                       'lonchura_2021_18km',\n",
    "                       'inter_2021_18km',\n",
    "                       'sub_2021_18km',\n",
    "                       'alpes_2021_18km', \n",
    "                       'hip_2021_18km', \n",
    "                       'c7_2021_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "        df09.rename(columns = {'c7_2021_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'quin_2021_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'axy_2021_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'hip_2021_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "        df09.rename(columns = {'trans_2021_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'quad_2021_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'exo_2021_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "        df09.rename(columns = {'api_2021_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'gla_2021_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'case_2021_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "        df09.rename(columns = {'inter_2021_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'monti_2021_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'sub_2021_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "        df09.rename(columns = {'cris_2021_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'plec_2021_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "        df09.rename(columns = {'phaino_2021_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'belli_2021_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'zono_2021_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "        df09.rename(columns = {'lonchura_2021_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'alpes_2021_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "        df09.rename(columns = {'aberti_2021_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "        df09.rename(columns = {'chl_2021_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "        ws100_preds = xgb_wrapper.predict(df09)\n",
    "        results = ws100_preds.sum()\n",
    "\n",
    "        list_2021.append(results)\n",
    "\n",
    "\n",
    "sum(list_2021)/len(list_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a722b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 고정 상수 제외\n",
    "df09 = df[['quin_2007_18km',\n",
    "           'trans_2007_18km',\n",
    "           'chl_2007_18km',\n",
    "           'cris_2007_18km',\n",
    "           'axy_2007_18km',\n",
    "           'quad_2007_18km',\n",
    "           'exo_2007_18km',           \n",
    "           'plec_2007_18km',\n",
    "           'phaino_2007_18km',\n",
    "           'aberti_2007_18km',\n",
    "           'belli_2007_18km',\n",
    "           'api_2007_18km',\n",
    "           'gla_2007_18km',\n",
    "           'case_2007_18km',\n",
    "           'monti_2007_18km',\n",
    "           'zono_2007_18km',\n",
    "           'lonchura_2007_18km',\n",
    "           'inter_2007_18km',\n",
    "           'sub_2007_18km',\n",
    "           'alpes_2007_18km', \n",
    "           'hip_2007_18km', \n",
    "           'c7_2007_18km']].reset_index(drop=True) # 상태를 알고싶은 년도의 변수\n",
    "\n",
    "\n",
    "df09.columns\n",
    "\n",
    "df09.rename(columns = {'c7_2007_18km' : 'Coccinella_septempunctata_18'}, inplace = True)\n",
    "df09.rename(columns = {'quin_2007_18km' : 'Hippodamia_quinquesignata_18'}, inplace = True) #\n",
    "df09.rename(columns = {'axy_2007_18km' : 'Harmonia_axyridis_18'}, inplace = True) #\n",
    "df09.rename(columns = {'hip_2007_18km' : 'Hippodamia_convergens_18'}, inplace = True)\n",
    "df09.rename(columns = {'trans_2007_18km' : 'Coccinella_transversoguttata_18'}, inplace = True) #\n",
    "df09.rename(columns = {'quad_2007_18km' : 'Hyperaspis_quadrioculata_18'}, inplace = True) #\n",
    "df09.rename(columns = {'exo_2007_18km' : 'Exochomus_aethiops_18'}, inplace = True)\n",
    "df09.rename(columns = {'api_2007_18km' : 'Hippodamia_apicalis_18'}, inplace = True) #\n",
    "df09.rename(columns = {'gla_2007_18km' : 'Hippodamia_glacialis_18'}, inplace = True) #\n",
    "df09.rename(columns = {'case_2007_18km' : 'Hippodamia_caseyi_18'}, inplace = True)\n",
    "df09.rename(columns = {'inter_2007_18km' : 'Myzia_interrupta_18'}, inplace = True) #\n",
    "df09.rename(columns = {'monti_2007_18km' : 'Coccinella_monticola_18'}, inplace = True) #\n",
    "df09.rename(columns = {'sub_2007_18km' : 'Subcoccinella_vigintiquatuorpunctata_18'}, inplace = True)\n",
    "df09.rename(columns = {'cris_2007_18km' : 'Melozone_crissalis_18'}, inplace = True) #\n",
    "df09.rename(columns = {'plec_2007_18km' : 'Plectrophenax_nivalis_18'}, inplace = True)\n",
    "df09.rename(columns = {'phaino_2007_18km' : 'Phainopepla_nitens_18'}, inplace = True) #\n",
    "df09.rename(columns = {'belli_2007_18km' : 'Artemisiospiza_belli_18'}, inplace = True) #\n",
    "df09.rename(columns = {'zono_2007_18km' : 'Zonotrichia_leucophrys_18'}, inplace = True)\n",
    "df09.rename(columns = {'lonchura_2007_18km' : 'Lonchura_punctulata_18'}, inplace = True) #\n",
    "df09.rename(columns = {'alpes_2007_18km' : 'Eremophila_alpestris_18'}, inplace = True) #\n",
    "df09.rename(columns = {'aberti_2007_18km' : 'Melozone_aberti_18'}, inplace = True)\n",
    "df09.rename(columns = {'chl_2007_18km' : 'Pipilo_chlorurus_18'}, inplace = True) #\n",
    "\n",
    "\n",
    "df09 = df09.iloc[[17, 122]]\n",
    "# df09[df09.Species=='Coccinella novemnotata'].reset_index(drop=True) # 실제 예측할 데이터 프레임\n",
    "\n",
    "ws100_preds = xgb_wrapper.predict(df09)\n",
    "ws100_preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2007,2022):\n",
    "        globals()['list_{}'.format(i)] = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f86af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ad1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c3d168",
   "metadata": {},
   "source": [
    "# 그 밖의 통계 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e62857",
   "metadata": {},
   "source": [
    "## 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce28275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정트리\n",
    "\n",
    "## 4년\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.2, random_state=3)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state = 4)\n",
    "\n",
    "dt_clf.fit(X_train, y_train) # label 과 feature가 함께 들어감\n",
    "\n",
    "pred = dt_clf.predict(X_test) # label 없이 feature만 들어감\n",
    "\n",
    "print('s 예측 정확도: {0:4f}'.format(accuracy_score(y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(xgb_wrapper[0], \n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='class',\n",
    "               feature_names=MCz.columns, \n",
    "               class_names=[0,1], \n",
    "               title=\"Decision Tree - Iris data set\")\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decision tree\n",
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(dt_clf, \n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='class',\n",
    "               feature_names=MCz.columns, \n",
    "               class_names=[0,1], \n",
    "               title=\"Decision Tree - Iris data set\")\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852099de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state를 500번 셔플한 결과들의 평균\n",
    "pot = list(range(0, 501))\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "\n",
    "\n",
    "for i in pot:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.2, random_state=i)\n",
    "\n",
    "    dt_clf = DecisionTreeClassifier(random_state = i)\n",
    "\n",
    "    dt_clf.fit(X_train, y_train) # label 과 feature가 함께 들어감\n",
    "\n",
    "    pred = dt_clf.predict(X_test) # label 없이 feature만 들어감\n",
    "\n",
    "    # 예측 성능 평가\n",
    "    a, b, c, d = get_clf_eval_num_easy(y_test, pred)\n",
    "    accuracys = accuracys + a\n",
    "    precisions = precisions + b\n",
    "    recalls = recalls + c\n",
    "    f1s = f1s + d\n",
    "    \n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "accuracys/len(pot)\n",
    "precisions/len(pot)\n",
    "recalls/len(pot)\n",
    "f1s/len(pot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ad82e",
   "metadata": {},
   "source": [
    "## 앙상블학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4719d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 / KNN(K-최근접 이웃 알고리즘)\n",
    "lr_clf = LogisticRegression(solver='liblinear') # 옵션\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8) # 옵션\n",
    "\n",
    "# 둘이 합쳐서\n",
    "vo_clf = VotingClassifier(estimators=[('LR', lr_clf), ('KNN', knn_clf)], voting='soft') # 옵션\n",
    "\n",
    "\n",
    "# 3. 학습 (데이터세트 분리) \n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<s>>>>>')\n",
    "\n",
    "# 데이터 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.2 , random_state= 156) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "#### voting 분류기\n",
    "# 학습/예측/평가\n",
    "vo_clf.fit(X_train,y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "# 평가\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "\n",
    "#### 개별일 때의 결과\n",
    "# 로지스틱 회귀와 KNN 각 개별 모델로 학습/예측/평가\n",
    "classifiers = [lr_clf,knn_clf]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__  # __class__ : 클래스명  # __name__ : 클래스명 추출\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda0c99",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "    sample = c92_copy2[:2005].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([c92_copy2[2006:], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    MCz= c92_copy22[DJ]\n",
    "    # MCz.drop(columns = 'target', inplace=True)\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        rf_clf = RandomForestClassifier(random_state=i)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        pred = rf_clf.predict(X_test)\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d = get_clf_eval_num_easy(y_test, pred)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3cff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=1000, max_depth=4, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "\n",
    "# 앞으로 계속 중요도 시각화를 죽 계속할 건데 이 코드를 계속 비슷하게 사용한다고 생각하면 됨\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns)\n",
    "# sort_values() 쉽게 하기 위해서 시리즈로 만들고, \n",
    "# 최고 중요도가 높은 20개 피처들만 추출\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "# x축은 중요도 값, y축은 ftr_top20 시리즈의 index\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbea4b2",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GBM 수행 시간을 측정하기 위한 time()객체 생성\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#### 4년 \n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<s>>>>>')\n",
    "\n",
    "# 데이터 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.2 , random_state= 156) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=99) # 모델 객체 생성\n",
    "gb_clf.fit(X_train, y_train) # 학습\n",
    "pred = gb_clf.predict(X_test)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print()\n",
    "print()\n",
    "print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "# random state를 500번 셔플한 결과들의 평균\n",
    "\n",
    "hot = list(range (0, 100))\n",
    "pot = list(range(0, 100))\n",
    "           \n",
    "T1 = 0\n",
    "T2 = 0\n",
    "T3 = 0\n",
    "T4 = 0\n",
    "T5 = 0\n",
    "\n",
    "accuracys = 0\n",
    "precisions = 0\n",
    "recalls = 0\n",
    "f1s = 0\n",
    "roc_aucs = 0\n",
    "           \n",
    "for k in tqdm(hot):\n",
    "    sample = c92_copy2[:2005].sample(n=294, random_state = k)\n",
    "    c92_copy22 = pd.concat([c92_copy2[2006:], sample])\n",
    "    \n",
    "    c92sr2_y = c92_copy22.target\n",
    "    MCz= c92_copy22[DJ]\n",
    "    # MCz.drop(columns = 'target', inplace=True)\n",
    "\n",
    "    for i in pot:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(MCz, c92sr2_y, test_size=0.1, random_state= i) # 정확도는 0.1일 때 가장 높음\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        gb_clf = GradientBoostingClassifier(random_state=i) # 모델 객체 생성\n",
    "        gb_clf.fit(X_train, y_train) # 학습\n",
    "        pred = gb_clf.predict(X_test)\n",
    "\n",
    "        # 예측 성능 평가\n",
    "        a, b, c, d = get_clf_eval_num_easy(y_test, pred)\n",
    "        accuracys = accuracys + a\n",
    "        precisions = precisions + b\n",
    "        recalls = recalls + c\n",
    "        f1s = f1s + d\n",
    "        roc_aucs = roc_aucs + e\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('<<<<주요종만sopr>>>>')\n",
    "\n",
    "    accuracys/len(pot)\n",
    "    precisions/len(pot)\n",
    "    recalls/len(pot)\n",
    "    f1s/len(pot)\n",
    "    roc_aucs/len(pot)\n",
    "               \n",
    "    T1 = T1 + (accuracys/len(pot))\n",
    "    T2 = T2 + (precisions/len(pot))\n",
    "    T3 = T3 + (recalls/len(pot))\n",
    "    T4 = T4 + (f1s/len(pot))\n",
    "    T5 = T5 + (roc_aucs/len(pot))\n",
    "    \n",
    "    accuracys = 0\n",
    "    precisions = 0\n",
    "    recalls = 0\n",
    "    f1s = 0\n",
    "    roc_aucs = 0\n",
    "           \n",
    "T1/len(hot)\n",
    "T2/len(hot)\n",
    "T3/len(hot)\n",
    "T4/len(hot)\n",
    "T5/len(hot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28448a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm을 구현하여 shap value를 예측할 것\n",
    "# ligthgbm 구현\n",
    "\n",
    "# library\n",
    "import lightgbm as lgb  # 없을 경우 cmd/anaconda prompt에서 install\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# lightgbm model\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10,\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 1000, # Number of trees\n",
    "            'objective': 'regression'} # 목적 함수 (L2 Loss)\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "lgb_model_predict = lgb_model.predict(test_x) # test data 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(lgb_model_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ce1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75e449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650e20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn01",
   "language": "python",
   "name": "sklearn01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "459px",
    "left": "1275px",
    "top": "249.125px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
